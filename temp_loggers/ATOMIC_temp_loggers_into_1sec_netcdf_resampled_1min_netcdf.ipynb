{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saildrone temperature logger processing code\n",
    "- This code reads in the full saildrone dataset to get start/stop times and metadata\n",
    "- It reads in the Saildrone provided .csv temperature logger files\n",
    "- There are several dictionaries that contain filename, serial number, depth data\n",
    "- These are then combined into a single file that matches the indices of the original saildrone data\n",
    "- lat and lon from the saildrone data are added to the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of file: 11\n"
     ]
    }
   ],
   "source": [
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seawater as sw\n",
    "import cartopy.crs as ccrs                   # import projections\n",
    "import cartopy.feature as cf                 # import features\n",
    "import uuid\n",
    "from scipy import interpolate\n",
    "from glob import glob\n",
    "\n",
    "#create xarray dataset with saildrone filenames\n",
    "#data directory for saildrone data\n",
    "data_dir = 'F:/data/cruise_data/saildrone/2020_atomic/'\n",
    "saildrone_filename=[data_dir+'/delay_mode/1060/1min/saildrone-gen_5-atomic_eurec4a_2020-sd1060-20200117T000000-20200302T235959-1_minutes-v1.1589306886594.nc',\n",
    "                    data_dir+'/delay_mode/1061/1min/saildrone-gen_5-atomic_eurec4a_2020-sd1061-20200117T000000-20200302T235959-1_minutes-v1.1589307121602.nc',\n",
    "                    data_dir+'/delay_mode/1026/1min/saildrone-gen_5-atomic_eurec4a_2020-sd1026-20200117T000000-20200302T235959-1_minutes-v1.1589306725934.nc'\n",
    "                   ]\n",
    "saildrone_filename_short=['saildrone-gen_5-atomic_eurec4a_2020-sd1060-20200117T000000-20200302T235959-1_minutes-v1.1589306886594.nc',\n",
    "                          'saildrone-gen_5-atomic_eurec4a_2020-sd1061-20200117T000000-20200302T235959-1_minutes-v1.1589307121602.nc',\n",
    "                          'saildrone-gen_5-atomic_eurec4a_2020-sd1026-20200117T000000-20200302T235959-1_minutes-v1.1589306725934.nc'\n",
    "                         ]\n",
    "\n",
    "usvs=[1060,1061,1026]\n",
    "\n",
    "ds_info_saildrone = xr.Dataset(data_vars={'fname':(['trajectory'],saildrone_filename),'fname_short':(['trajectory'],saildrone_filename_short)},coords={'trajectory':usvs})\n",
    "\n",
    "\n",
    "#data direcgtory for temperature logger .csv files\n",
    "adir_sbe='F:/data/cruise_data/saildrone/2020_atomic/keel-mount-temp-loggers/'\n",
    "\n",
    "#get list of all filenames in directory\n",
    "files = [x for x in glob(adir_sbe+'*.csv')]\n",
    "print('number of file:',len(files))\n",
    "#print(files)\n",
    "\n",
    "#time_start = '2019-05-14T23:00:00'\n",
    "#time_end = '2019-10-11T18:30:00'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tem=df[df.vehicle==1060] \n",
    "#tem=tem[tem.serial_num==76102]\n",
    "#df[df.serial_num==76102].depth.values\n",
    "#print(tem.depth.values)\n",
    "#iserial=76101\n",
    "#df[df.serial_num==iserial].depth.values[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make ds_info to store all the temperature logger info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get list of all filenames in directory\n",
    "#files = [x for x in glob(adir_sbe+'*.csv')]\n",
    "#print('number of file:',len(files))\n",
    "#RBR Solot\n",
    "#Special Note: S/N 76106 unexpectedly stopped recording before the mission days began\n",
    "data = {'vehicle':  [1060,1060,1060,1060,1061,1061,1061,1061,1026,1026,1026,1026],\n",
    "        'serial_num': [76102,101317,76104,76106,101315,76111,100036,76110,76108,76109,100038,76103],\n",
    "        'depth': [.4,.85,1.3,1.8,.4,.85,1.3,1.8,.4,.85,1.3,1.8]\n",
    "        }\n",
    "df = pd.DataFrame (data, columns = ['vehicle','serial_num','depth'])\n",
    "\n",
    "#df[df.vehicle==1026].serial_num\n",
    "adepth=[]\n",
    "astr=[]\n",
    "anum=[]\n",
    "\n",
    "for iusv in usvs:\n",
    "    adepth2=[]\n",
    "    astr2=[]\n",
    "    anum2=[]\n",
    "    for file in files:\n",
    "        ii=file.find('\\\\')\n",
    "        iserial=int(file[ii+1:ii+7])\n",
    "        #print(iserial)\n",
    "        idepth=df[df.serial_num==iserial].depth.values[0]\n",
    "        iusv2=df[df.serial_num==iserial].vehicle.values[0]\n",
    "        if iusv2==iusv:\n",
    "            astr2.append(file[ii+1:])\n",
    "            anum2.append(iserial)\n",
    "            adepth2.append(idepth)\n",
    "    if iusv==1060:\n",
    "        astr2.append('not_exist')\n",
    "        anum2.append(76106)\n",
    "        adepth2.append(1.8)\n",
    "    sort_index = np.argsort(adepth2)\n",
    "    #sort by depth\n",
    "    adepth3,astr3,anum3,=[],[],[]\n",
    "    for i in range(len(adepth2)):\n",
    "        adepth3.append(adepth2[sort_index[i]])\n",
    "        astr3.append(astr2[sort_index[i]])\n",
    "        anum3.append(anum2[sort_index[i]])\n",
    "    adepth.append(adepth3)\n",
    "    astr.append(astr3)\n",
    "    anum.append(anum3)\n",
    "\n",
    "ds_info = xr.Dataset(data_vars={'fname':(['trajectory','z'],astr),\n",
    "                                'depth':(['trajectory','z'],adepth),\n",
    "                                'serial':(['trajectory','z'],anum)},\n",
    "                     coords={'z':np.arange(4),'trajectory':usvs})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Metadata\n",
    "- SBE56 info, set some attributes and depths for metadata\n",
    "- put filenames and depts into a xarray dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoding_str={\n",
    "      'sea_water_temperature_00': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_01': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_02': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_03': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_04': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_05': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_06': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'time':{'dtype':'float64', '_FillValue': -9999},\n",
    "      'latitude':{'dtype':'float64', '_FillValue': -9999},\n",
    "      'longitude':{'dtype':'float64', '_FillValue': -9999}\n",
    "      }\n",
    "\n",
    "#lat_attrs = {\"_FillValue\":np.nan,\n",
    "lat_attrs = {'long_name':'latitude',\n",
    "             'standard_name':'latitude',\n",
    "             'units':'degrees_north',\n",
    "             'coverage_content_type':'coordinate',\n",
    "             'axis':'Y',\n",
    "             'valid_max':90.0,\n",
    "             'valid_min':-90.0}\n",
    "             \n",
    "#lon_attrs = {\"_FillValue\":np.nan,\n",
    "lon_attrs = {'long_name':'longitude',\n",
    "             'standard_name':'longitude',\n",
    "             'units':'degrees_east',\n",
    "             'coverage_content_type':'coordinate',\n",
    "             'axis':'X',\n",
    "             'valid_max':180.0,\n",
    "             'valid_min':-180.0}\n",
    "\n",
    "vattrs = {'long_name': 'sea surface temperature at',\n",
    "          'standard_name': 'sea_water_temperature', 'installed_height':'-0.295 m' ,\n",
    "          'serial_number' : 'RBR05608196', 'model_number': 'solo_t', \n",
    "          'sensor_description': 'RBR Solo Temperature Logger',\n",
    "          'model_name': 'RBR_Solo_t', 'product_page':'https://rbr-global.com/products/compact-loggers/rbrsolo-t', \n",
    "          'nominal_sampling_schedule': '1 sec', \n",
    "          'units':'degrees_C','valid_min':-5.0,'valid_max':50.0}#,'_FillValue':-9.9}\n",
    "\n",
    "tattrs = {'long_name':'time',\n",
    "          'standard_name':'time',\n",
    "          'coverage_content_type':'coordinate',\n",
    "          'axis':'T'}\n",
    "\n",
    "encoding_str_log={\n",
    "      'sea_water_temperature_00_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_01_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_02_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_03_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_04_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_05_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_06_mean': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_00_std': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_01_std': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_02_std': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_03_std': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_04_std': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_05_std': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'sea_water_temperature_06_std': {'dtype': 'int16', 'scale_factor': 0.001, '_FillValue': -9999},\n",
    "      'time':{'dtype':'float64', '_FillValue': -9999},\n",
    "      'latitude':{'dtype':'float64', '_FillValue': -9999},\n",
    "      'longitude':{'dtype':'float64', '_FillValue': -9999}\n",
    "      }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine the .cvs files into a single netcdf file with metadata\n",
    "\n",
    "- for sbe3 on 1036, it fell off, so i put nan for that one\n",
    "- for several 1037 they stopped at different dates so i filled with nan at end to make same length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds_sbe=[]\n",
    "del ds_sbe\n",
    "iobs_start=0\n",
    "for iusv,usv in enumerate(usvs):   #loop over vehicles\n",
    "    print(usv,iusv)\n",
    "#    if iusv==0:\n",
    "#        continue\n",
    "    fname = str(ds_info_saildrone.sel(trajectory=usv).fname.data)\n",
    "#    fname=saildrone_filename[iusv]\n",
    "#    fname_out=sbe_filename[iusv]\n",
    "    ds = xr.open_dataset(fname)\n",
    "    ds.close()\n",
    "    gattrs=ds.attrs \n",
    "#    time_start,time_stop = ds.time[0,0].data,ds.time[0,-1].data\n",
    "    \n",
    "    for iz in range(7):   #loop over SBEs \n",
    "        \n",
    "        #vname='sea_water_temperature_'+str(iz).zfill(2)\n",
    "        print(usv,iz) #,xf.time.min().data,xf.time.max().data)\n",
    "        \n",
    "        #read in the data and rename variable\n",
    "        if ((usv==1060) and (iz==3)) or iz>3:  #the third sbe56 fell off & file doesn't exist\n",
    "            vname2='sea_water_temperature_'+str(iz).zfill(2)\n",
    "            xf=xf.rename({vname:vname2})\n",
    "            xf[vname2]=xf[vname2]*np.nan\n",
    "            vname='sea_water_temperature_'+str(iz).zfill(2)\n",
    "        else:\n",
    "            #create the .csv SBE filename to read in\n",
    "            vname='sea_water_temperature_'+str(iz).zfill(2)\n",
    "            tem = ds_info.sel(trajectory=usv).isel(z=iz)\n",
    "            filename = adir_sbe + str(tem.fname.data)\n",
    "            print(filename)\n",
    "            df = pd.read_csv(filename,header=0,names=['time','temp'],skiprows=16)\n",
    "            tt = df['time']\n",
    "            tt=tt.replace(\" \",\"T\")\n",
    "            t2=pd.to_datetime(tt)\n",
    "            df['time']=t2\n",
    "            df.index=df['time']\n",
    "            xf=df.to_xarray()\n",
    "            xf=xf.rename({'temp':vname})    \n",
    "            vattrs['installed_height']=str(-1*ds_info.sel(trajectory=usv).isel(z=iz).depth.data)+' m'\n",
    "            vattrs['serial_number']=ds_info.sel(trajectory=usv).isel(z=iz).serial.data\n",
    "            vattrs['long_name']='sea surface temperature at '+str(ds_info.sel(trajectory=usv).isel(z=iz).depth.data)+' meters depth'\n",
    "            xf.attrs=vattrs\n",
    "\n",
    "        if iz==0:\n",
    "            time_start2,time_stop2 = ds.time[0,0].data,ds.time[0,-1].data\n",
    "            time_start,time_stop = xf.time[0].data,xf.time[-1].data\n",
    "            time_start = max([time_start,time_start2])\n",
    "            time_stop = min([time_stop,time_stop2])\n",
    "\n",
    "\n",
    "        xf = xf.sel(time=slice(time_start,time_stop))\n",
    "#        print('TIME')\n",
    "#        print(xf.time[0].data,xf.time[-1].data)\n",
    "#        print(len(xf.time))\n",
    "   #    tem = ds_sbe.where(ds_sbe.time>=np.datetime64('2020-01-17T00:00:00'),drop=True)\n",
    "#    tem = tem.where(tem.time<=np.datetime64('2020-03-02T23:59:00'),drop=True)\n",
    "\n",
    "        \n",
    "        if iz==0:\n",
    "            nobs_start=xf.time.size\n",
    "            \n",
    "        iobs=np.arange(xf.time.size)\n",
    "        nobs=xf.time.size\n",
    "        \n",
    "        if nobs_start>nobs:\n",
    "            xf_save = xf_save.rename({vname_save:vname})\n",
    "            xf = xr.concat([xf.sel(time=slice(xf.time[0],xf.time[-2])),xf_save.sel(time=slice(xf.time[-1],xf_save.time[-1]))*np.nan],dim='time')\n",
    "        \n",
    "        #fix gap in data in 076110 file\n",
    "        if iz==3 and usv==1061:\n",
    "            xf0=xf.isel(time=slice(0,2983269))\n",
    "            xf1=xf.isel(time=slice(2983269,len(xf.time)))\n",
    "            xf_insert = xf_save.isel(time=slice(2983269,2983269+17000))\n",
    "            xf_insert['sea_water_temperature_03']=xf_insert.sea_water_temperature_03*np.nan\n",
    "            xf_fill=xr.concat([xf0,xf_insert,xf1],dim='time')\n",
    "            xf = xf_fill\n",
    "            \n",
    "        if iz==0:\n",
    "            td=np.ones((1,xf.time.size))*np.nan\n",
    "            td[0,:]=xf[vname] #vname\n",
    "            ds_sbe=xr.Dataset(data_vars={vname:(['trajectory','obs'],td)},coords={'trajectory':[usv]})\n",
    "            ds_sbe[vname].attrs=vattrs\n",
    "        else:\n",
    "            td=np.ones((1,xf.time.size))*np.nan\n",
    "            ds_sbe2=xr.Dataset(data_vars={vname:(['trajectory','obs'],td)},coords={'trajectory':[usv]})\n",
    "            ds_sbe2[vname][0,:]=xf[vname].data\n",
    "            ds_sbe2[vname].attrs=vattrs\n",
    "            ds_sbe = xr.merge([ds_sbe,ds_sbe2])\n",
    "\n",
    "        xf_save=xf\n",
    "        vname_save=vname\n",
    "        #print(ds_sbe.trajectory)\n",
    "    td=np.zeros((1,xf.time.size), dtype='datetime64[s]')\n",
    "    td[0,:]=xf.time.data\n",
    "    tem=xr.Dataset(data_vars={'time':(['trajectory','obs'],td)},coords={'trajectory':[usv]})\n",
    "    ds_sbe = xr.merge([ds_sbe,tem])\n",
    "    ds_sbe=ds_sbe.assign_coords(time=ds_sbe.time)\n",
    "    gattrs['time_coverage_resolution']='PT2S'\n",
    "    gattrs['uuid']=str(uuid.uuid4())\n",
    "    gattrs['keywords']='Temperature, Saildrone, Arctic, Bering Sea, Chukchi Sea, NASA, NOAA'\n",
    "    gattrs['history']='created post-cruise by Gentemann 3/25/2020'  \n",
    "    ds_sbe['trajectory']=ds.trajectory\n",
    "    \n",
    "#add lat and lon and time\n",
    "    flat = interpolate.interp1d(ds.time[0,:].astype('float64'),ds.latitude[0,:])\n",
    "    newlat = flat(ds_sbe.time[0,:].astype('float64'))\n",
    "    flon = interpolate.interp1d(ds.time[0,:].astype('float64'),ds.longitude[0,:])\n",
    "    newlon = flon(ds_sbe.time[0,:].astype('float64'))\n",
    "    td=np.zeros((1,xf.time.size), dtype='double')\n",
    "    td[0,:]=newlat\n",
    "#    tem=xr.Dataset(data_vars={'latitude':(['trajectory','obs'],td)},coords={'trajectory':[usv]})\n",
    "    tem=xr.Dataset(data_vars={'latitude':(['trajectory','obs'],td)},coords={'trajectory':ds_sbe.trajectory})\n",
    "#    print('****')\n",
    "#    print(tem)\n",
    "#    print('****')\n",
    "    ds_sbe = xr.merge([ds_sbe,tem])\n",
    "    ds_sbe=ds_sbe.assign_coords(latitude=ds_sbe.latitude)\n",
    "    td=np.zeros((1,xf.time.size), dtype='double')\n",
    "    td[0,:]=newlon\n",
    "    tem=xr.Dataset(data_vars={'longitude':(['trajectory','obs'],td)},coords={'trajectory':ds_sbe.trajectory})\n",
    "    ds_sbe = xr.merge([ds_sbe,tem])\n",
    "    ds_sbe=ds_sbe.assign_coords(longitude=ds_sbe.longitude)\n",
    "    ds_sbe.latitude.attrs=lat_attrs\n",
    "    ds_sbe.longitude.attrs=lon_attrs\n",
    "    ds_sbe.time.attrs=tattrs\n",
    "    ds_sbe.trajectory.attrs={'cf_role':'trajectory_id'}\n",
    "    ds_sbe.attrs=gattrs\n",
    "\n",
    "    \n",
    "    fname = str(ds_info_saildrone.sel(trajectory=usv).fname_short.data)\n",
    "    beg_fname = 'temperature_loggers-atomic_eurec4a_2020-sd'+str(usv)+'-20200117T000000-20200302T235959-1_second-v1.nc'\n",
    "    fout=data_dir+'/temp_log_proc/'+beg_fname\n",
    "\n",
    "#output data\n",
    "    ds_sbe.to_netcdf(fout,encoding=encoding_str)\n",
    "    del ds_sbe\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create files with 1 minute averages of data using :54 to :06 seconds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1061 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gentemann\\Miniconda3\\envs\\satenv\\lib\\site-packages\\xarray\\core\\nanops.py:142: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1026 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gentemann\\Miniconda3\\envs\\satenv\\lib\\site-packages\\xarray\\core\\nanops.py:142: RuntimeWarning: Mean of empty slice\n",
      "  return np.nanmean(a, axis=axis, dtype=dtype)\n"
     ]
    }
   ],
   "source": [
    "#make 1min average data\n",
    "#iusv=0\n",
    "#usv=1060\n",
    "for iusv,usv in enumerate(usvs):   #loop over vehicles\n",
    "#    if iusv==0:\n",
    "#        continue\n",
    "    print(usv,iusv)\n",
    "    avehicle=str(usv)\n",
    "    beg_fname = 'temperature_loggers-atomic_eurec4a_2020-sd'+str(usv)+'-20200117T000000-20200302T235959-1_second-v1.nc'\n",
    "    filename=data_dir+'/temp_log_proc/'+beg_fname\n",
    "    beg_fname = 'temperature_loggers-atomic_eurec4a_2020-sd'+str(usv)+'-20200117T000000-20200302T235959-1_minute-v1.nc'\n",
    "    filename_out=data_dir+'/temp_log_proc/'+beg_fname\n",
    "    xf=xr.open_dataset(filename)\n",
    "    offset = pd.to_timedelta(6, unit='s') \n",
    "    xftem=xf\n",
    "    xftem = xftem.isel(trajectory=0)\n",
    "    xftem = xftem.swap_dims({'obs':'time'})\n",
    "    #offset time by 6 seconds then mask all data outside first 12 which acutally is :54 to :06\n",
    "    pt = pd.to_datetime(xftem.time.data+offset)\n",
    "    psec=pt.second\n",
    "    tem=xftem.where(psec <=12)  #data average should be only use sec 54 to sec 06 of each minute \n",
    "    tem['time']=tem['time']+offset #resample goes from :00 to :59 so shift +6sec\n",
    "    #resample data to 1min\n",
    "    xf_avg1 = tem.resample(time='1min').mean(keep_attrs=True)\n",
    "    xf_std1 = tem.resample(time='1min').std(ddof=1,keep_attrs=True)\n",
    "    for var in xf_avg1:\n",
    "        var2=var+'_mean'\n",
    "        sattrs=xf_avg1[var].attrs\n",
    "        xf_avg1 = xf_avg1.rename({var:var2})\n",
    "        sattrs['nominal_sampling_schedule']='1 minute averages from :54 to :06 seconds'\n",
    "        sattrs['long_name']='sea surface depth 1-min mean'\n",
    "        xf_avg1[var2].attrs=sattrs\n",
    "        sattrs['long_name']='sea surface depth 1-min standard dev'\n",
    "    for var in xf_std1:\n",
    "        var2 = var+'_std'\n",
    "        sattrs=xf_std1[var].attrs\n",
    "        xf_std1 = xf_std1.rename({var:var2})\n",
    "        sattrs['nominal_sampling_schedule']='1 minute averages from :54 to :06 seconds'\n",
    "        sattrs['long_name']='sea surface depth 1-min standard dev'\n",
    "        xf_std1[var2].attrs=sattrs\n",
    "    \n",
    "    ds_sbe=[]\n",
    "    ds_usv = xr.open_dataset(saildrone_filename[0])\n",
    "    ds_usv.close()\n",
    "    gattrs=ds_usv.attrs \n",
    "    for ivname,vname in enumerate(xf_avg1):\n",
    "        if ivname==0:\n",
    "            td=np.ones((1,xf_avg1.time.size))*np.nan\n",
    "            td[0,:]=xf_avg1[vname].data #vname\n",
    "            ds_sbe=xr.Dataset(data_vars={vname:(['trajectory','obs'],td)},coords={'trajectory':ds_usv.trajectory})\n",
    "            ds_sbe[vname].attrs=xf_avg1[vname].attrs\n",
    "        else:\n",
    "            td=np.ones((1,xf_avg1.time.size))*np.nan\n",
    "            td[0,:]=xf_avg1[vname].data #vname\n",
    "            ds_sbe2=xr.Dataset(data_vars={vname:(['trajectory','obs'],td)},coords={'trajectory':ds_usv.trajectory})\n",
    "            ds_sbe2[vname].attrs=xf_avg1[vname].attrs\n",
    "            ds_sbe = xr.merge([ds_sbe,ds_sbe2])\n",
    "    for ivname,vname in enumerate(xf_std1):\n",
    "        td=np.ones((1,xf_std1.time.size))*np.nan\n",
    "        td[0,:]=xf_std1[vname].data #vname\n",
    "        ds_sbe2=xr.Dataset(data_vars={vname:(['trajectory','obs'],td)},coords={'trajectory':ds_usv.trajectory})\n",
    "        ds_sbe2[vname].attrs=xf_std1[vname].attrs\n",
    "        ds_sbe = xr.merge([ds_sbe,ds_sbe2])\n",
    "        \n",
    "    #add lat/lon from USV\n",
    "    td=np.zeros((1,ds_usv.time.size), dtype='double')\n",
    "    td[0,:]=ds_usv.latitude.data\n",
    "    tem=xr.Dataset(data_vars={'latitude':(['trajectory','obs'],td)},coords={'trajectory':ds_sbe.trajectory})\n",
    "    ds_sbe = xr.merge([ds_sbe,tem])\n",
    "    td=np.zeros((1,ds_usv.time.size), dtype='double')\n",
    "    td[0,:]=ds_usv.longitude.data\n",
    "    tem=xr.Dataset(data_vars={'longitude':(['trajectory','obs'],td)},coords={'trajectory':ds_sbe.trajectory})\n",
    "    ds_sbe = xr.merge([ds_sbe,tem])\n",
    "    td=np.zeros((1,ds_usv.time.size), dtype='datetime64[ns]')\n",
    "    td[0,:]=ds_usv.time.data\n",
    "    tem=xr.Dataset(data_vars={'time':(['trajectory','obs'],td)},coords={'trajectory':ds_sbe.trajectory})\n",
    "    ds_sbe = xr.merge([ds_sbe,tem])\n",
    "    \n",
    "    ds_sbe.latitude.attrs=lat_attrs\n",
    "    ds_sbe.longitude.attrs=lon_attrs\n",
    "    ds_sbe.time.attrs=tattrs\n",
    "    ds_sbe.trajectory.attrs={'cf_role':'trajectory_id'}\n",
    "    ds_sbe.attrs=gattrs\n",
    "\n",
    "    ds_sbe.to_netcdf(filename_out,encoding=encoding_str_log)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
