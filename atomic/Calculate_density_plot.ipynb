{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# figures for ATOMIC paper\n",
    "\n",
    "- timeseries of data & collocations with products\n",
    "- spectrums "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mticker\n",
    "from cartopy.mpl.gridliner import LONGITUDE_FORMATTER, LATITUDE_FORMATTER\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seawater as sw\n",
    "import cartopy.crs as ccrs                   # import projections\n",
    "import cartopy.feature as cf                 # import features\n",
    "import uuid\n",
    "from scipy import interpolate\n",
    "from scipy import signal\n",
    "from glob import glob\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import ticker, cm\n",
    "import matplotlib.colors as colors\n",
    "import datetime as dt\n",
    "import scipy.ndimage\n",
    "import spectrum\n",
    "\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0)\n",
    "\n",
    "#create xarray dataset with saildrone filenames\n",
    "#data directory for saildrone data\n",
    "data_dir = 'C:/Users/gentemann/Google Drive/public/2019_saildrone/ATOMIC/saildrone_usv_data/'\n",
    "saildrone_filenames = [x for x in glob(data_dir+'saildrone*.nc')]\n",
    "\n",
    "#data direcgtory for temperature logger .csv files\n",
    "data_dir = 'C:/Users/gentemann/Google Drive/public/2019_saildrone/ATOMIC/temp_log_proc/'\n",
    "#adir_sbe='F:/data/cruise_data/saildrone/2020_atomic/temp_log_proc/'\n",
    "\n",
    "#data direcgtory for temperature logger .csv files\n",
    "figs_dir = 'C:/Users/gentemann/Google Drive/public/2019_saildrone/ATOMIC/figs/'\n",
    "\n",
    "#get list of all filenames in directory\n",
    "logger_filenames = [x for x in glob(data_dir+'*1_min*.nc')]\n",
    "#print('number of file:',len(files))\n",
    "#print(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#subroutines for calculating PSD & making plot\n",
    "\n",
    "def spectrum(data_in):\n",
    "    #calculate PSD for each USV\n",
    "    data_all=[]\n",
    "    for iusv in range(3):\n",
    "        ds_usv = data_in.isel(trajectory=iusv)\n",
    "        ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "        ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "        dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08)\n",
    "        ds4 = ds3.interp(dist_total=dist_interp)\n",
    "        den = ds4.density_mean.interpolate_na(dim='dist_total')\n",
    "        den = den.where(np.isfinite(den),drop=True)\n",
    "        ds4_detrend = signal.detrend(den)\n",
    "        ds4_detrend_smooth = scipy.ndimage.filters.gaussian_filter1d(ds4_detrend, sigma=25)\n",
    "        freq, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/.080)  #fs = sampled at .08km or 80m\n",
    "        freq2, Pxx_den2 = signal.welch(ds4_detrend_smooth,1/.080,nperseg=1024*30)  #fs = sampled at .08km or 80m\n",
    "        if iusv==0:\n",
    "            ps_all=Pxx_den[0:10000]\n",
    "            ps_all_welch=Pxx_den2[0:10000]\n",
    "        else:\n",
    "            ps_all = np.vstack([ps_all,Pxx_den[0:10000]])\n",
    "            ps_all_welch = np.vstack([ps_all_welch,Pxx_den2[0:10000]])    \n",
    "    Pxx_den = np.mean(ps_all,axis=0)\n",
    "    Pxx_den_welch = np.mean(ps_all_welch,axis=0)\n",
    "    return freq,freq2,Pxx_den,Pxx_den_welch\n",
    "\n",
    "def spectrum_time(data_in):\n",
    "    #calculate PSD for each USV\n",
    "    data_all=[]\n",
    "    for iusv in range(3):\n",
    "        ds_usv = data_in.isel(trajectory=iusv)\n",
    "#        ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "#        ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "#        dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08)\n",
    "#        ds4 = ds3.interp(dist_total=dist_interp)\n",
    "        den = ds_usv.density_mean.interpolate_na(dim='dist_total')\n",
    "        den = den.where(np.isfinite(den),drop=True)\n",
    "        ds4_detrend_smooth = signal.detrend(den)\n",
    "        #ds4_detrend_smooth = scipy.ndimage.filters.gaussian_filter1d(ds4_detrend, sigma=25)\n",
    "        freq, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/1)  #fs = sampled at 1 min\n",
    "        freq2, Pxx_den2 = signal.welch(ds4_detrend_smooth,1/1,nperseg=1024*30)  #fs = sampled at 1 min\n",
    "        if iusv==0:\n",
    "            ps_all=Pxx_den[0:10000]\n",
    "            ps_all_welch=Pxx_den2[0:10000]\n",
    "        else:\n",
    "            ps_all = np.vstack([ps_all,Pxx_den[0:10000]])\n",
    "            ps_all_welch = np.vstack([ps_all_welch,Pxx_den2[0:10000]])    \n",
    "    Pxx_den = np.mean(ps_all,axis=0)\n",
    "    Pxx_den_welch = np.mean(ps_all_welch,axis=0)\n",
    "    return freq,freq2,Pxx_den,Pxx_den_welch\n",
    "\n",
    "\n",
    "def cal_pdf(data_in): \n",
    "    #make arrays for sampling at different length scales\n",
    "    length_scale = np.arange(.1,200,1)\n",
    "    # create the empty data arrays to store the normalized histograms (normalized the *100 for percentage count)\n",
    "    xx_in = np.arange(0,.2,.001)\n",
    "    xx_in2 = np.arange(0,.2-.001,.001)\n",
    "    data = np.zeros((len(length_scale),len(xx_in2)))\n",
    "    ddn=xr.DataArray(data,dims=('length_scale','gradx'),coords={'length_scale':length_scale,'gradx':xx_in2})\n",
    "    for iusv in range(3):\n",
    "        ds_usv = data_in.isel(trajectory=iusv)\n",
    "        ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)  #add dist traveled coordinate\n",
    "        ds3 = ds2.swap_dims({'time':'dist_total'})                  #swap from time to distance traveled\n",
    "        for ilen2,len2 in enumerate(length_scale):\n",
    "            dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],len2)\n",
    "            ds4 = ds3.interp(dist_total=dist_interp)       \n",
    "            den_grad =  np.abs(np.gradient(ds4.density_mean)/len2)\n",
    "            result,xx = np.histogram(den_grad,bins=xx_in)\n",
    "            ddn[ilen2,:]=ddn[ilen2,:]+result\n",
    "    for ilen2,len2 in enumerate(length_scale):\n",
    "        ddn[ilen2,:]=ddn[ilen2,:]/sum(ddn[ilen2,:])*100  #normalize & turn into percent\n",
    "\n",
    "    return ddn\n",
    "\n",
    "\n",
    "def psd_fig(f,data_in,Pxx_den,text1,fout,ifit):\n",
    "   \n",
    "    length_scale = np.arange(.1,200,1)\n",
    "    xx_in = np.arange(0,.2,.001)\n",
    "    xx_in2 = np.arange(0,.2-.001,.001)\n",
    "    print(len(length_scale),len(xx_in))\n",
    "    fig = plt.figure(figsize=(14,10))\n",
    "    tem=data_in\n",
    "    tem = tem.where(tem>.003)\n",
    "    Z=tem.T\n",
    "    ax = plt.pcolormesh(length_scale,xx_in2,Z, norm=colors.LogNorm(vmin=Z.min(), vmax=Z.max()),vmin=.01,vmax=100,cmap='hot')\n",
    "    plt.text(25,0.178,'(a)'+text1,fontsize=16,color='k')\n",
    "    plt.xlabel('Length scale (km)',fontsize=16)\n",
    "    plt.ylabel('Density gradient (kg m$^{-3}$ km$^{-1}$)',fontsize=16)\n",
    "    cb = plt.colorbar()\n",
    "    cb.set_label(label='Percent count',fontsize=16)\n",
    "\n",
    "    plt.axes([.43, .57, .3, .3])\n",
    "\n",
    "    #cal PSD\n",
    "    #Pxx_den = np.mean(psd_in,axis=0)\n",
    "    #f, Pxx_den = signal.periodogram(Pxx_den,1/.080)  #fs = sampled at .08km or 80m\n",
    "    istart,iend=10,5550\n",
    "    plt.loglog(f[istart:iend], Pxx_den[istart:iend])\n",
    "\n",
    "    #linear regression to PSD\n",
    "    istart,iend=8,ifit\n",
    "    XX = np.log(f[istart:iend])\n",
    "    YY = np.log(Pxx_den[istart:iend])\n",
    "    reg = LinearRegression().fit(XX.reshape(-1, 1), YY)\n",
    "    a = float(reg.coef_)\n",
    "    b = -1*float(reg.intercept_)\n",
    "    plt.loglog(f[istart:iend], f[istart:iend]**(a)/np.exp(b),'r') #test from fit\n",
    "    slp_str = 'slope = '+\"{:.1f}\".format(a)\n",
    "    plt.text(.02,10,slp_str,fontsize=16,color='r')\n",
    "    plt.ylim([10e-6,10e1])\n",
    "    plt.xlim([10e-4,10e-1])\n",
    "    plt.xticks(ticks=[.001,.01,.1,1],labels=['1000','100','10','1'])\n",
    "\n",
    "    plt.text(.0011,2,'(b)',fontsize=16,color='k')\n",
    "    #plt.xlabel('Wavenumber (cpkm)')\n",
    "    plt.xlabel('Wavelength (km)')\n",
    "    plt.ylabel('PSD ((kg m$^{-3}$)$^2$ cpkm$^{-1}$]')\n",
    "    plt.grid()\n",
    "    plt.savefig(figs_dir+fout)\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in USV data for all 3 Saildrone\n",
    "- caluclate density and wind speed\n",
    "- caluclate distance between successive obs\n",
    "- caluculate total cumulative distance\n",
    "- switch from time to cumulative distance as index\n",
    "- interpolate data onto grid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds=[]\n",
    "for iusv in range(3):\n",
    "    fname=saildrone_filenames[iusv]\n",
    "    ds_usv=xr.open_dataset(fname).isel(trajectory=0).swap_dims({'obs':'time'})\n",
    "    ds_usv.close()\n",
    "\n",
    "    #make diruanl plot\n",
    "    xlon=ds_usv.longitude.data\n",
    "    time_offset_to_lmt=(xlon/360.)*24.*60\n",
    "    tem = ds_usv.time+time_offset_to_lmt*np.timedelta64(1,'m')# dt.timedelta(seconds=1)\n",
    "    ds_usv['tlmt']=tem\n",
    "\n",
    "# try calculating diurnal variability as minimimum for given day\n",
    "#    ds_usv2= ds_usv.swap_dims({'time':'tlmt'})\n",
    "#    dymin = ds_usv2.groupby(\"tlmt.dayofyear\").min()\n",
    "#    ds_usv3 = ds_usv2.groupby(\"tlmt.dayofyear\") - dymin\n",
    "    #cal diurnal by subtracting mean from 6am hour\n",
    "    ds_usv2= ds_usv.swap_dims({'time':'tlmt'})\n",
    "    ds_usv2a = ds_usv2.where(ds_usv2.tlmt.dt.hour==6)\n",
    "    dymn = ds_usv2a.groupby(\"tlmt.dayofyear\").mean()\n",
    "    ds_usv3 = ds_usv2.groupby(\"tlmt.dayofyear\") - dymn\n",
    "\n",
    "#    tem,ttem,atem=[],ds_usv.TEMP_SBE37_MEAN[0],ds_usv.TEMP_AIR_MEAN[0]\n",
    "#    ds_sea = ds_usv.TEMP_SBE37_MEAN.copy(deep=True)\n",
    "#    ds_air = ds_usv.TEMP_SBE37_MEAN.copy(deep=True)\n",
    "#    for i in range(len(ds_sea)):\n",
    "#        xhr = int(ds_usv.tlmt.dt.minute[i])\n",
    "#        xmin = int(ds_usv.tlmt.dt.minute[i])\n",
    "#        if (xhr==5) & (xmin==0):\n",
    "#            ttem,atem=ds_usv.TEMP_SBE37_MEAN[i],ds_usv.TEMP_AIR_MEAN[i]\n",
    "#        ds_sea[i]=ds_usv.TEMP_SBE37_MEAN[i]-ttem\n",
    "#        ds_air[i]=ds_usv.TEMP_AIR_MEAN[i]-atem\n",
    "#    ds_usv['dw_sea']=ds_sea\n",
    "#    ds_usv['dw_air']=ds_air\n",
    "#    ds_usv = add_den_usv(ds_usv)\n",
    "#    ds_usv = add_flux_usv(ds_usv,1.0)   \n",
    "    \n",
    "    ds_usv['TEMP_AIR_MEAN_DW'] = ds_usv3.swap_dims({'tlmt':'time'}).drop({'tlmt'}).TEMP_AIR_MEAN\n",
    "    ds_usv['TEMP_SBE37_MEAN_DW'] = ds_usv3.swap_dims({'tlmt':'time'}).drop({'tlmt'}).TEMP_SBE37_MEAN\n",
    "    ds_usv['wspd']=np.sqrt(ds_usv.UWND_MEAN**2+ds_usv.VWND_MEAN**2)   \n",
    "    tem=sw.dens0(ds_usv.SAL_SBE37_MEAN,ds_usv.TEMP_SBE37_MEAN)\n",
    "    ds_usv['density_mean']=xr.DataArray(tem,dims=('time'),coords={'time':ds_usv.time})\n",
    "    tem=sw.alpha(ds_usv.SAL_SBE37_MEAN,ds_usv.TEMP_SBE37_MEAN,ds_usv.BARO_PRES_MEAN*0) #pressure =0 at surface\n",
    "    ds_usv['alpha_ME']=xr.DataArray(tem,dims=('time'),coords={'time':ds_usv.time})\n",
    "    tem=sw.beta(ds_usv.SAL_SBE37_MEAN,ds_usv.TEMP_SBE37_MEAN,ds_usv.BARO_PRES_MEAN*0) #pressure =0 at surface\n",
    "    ds_usv['beta_MEAN']=xr.DataArray(tem,dims=('time'),coords={'time':ds_usv.time})\n",
    "    ds_usv['latitude']=ds_usv.latitude.interpolate_na(dim='time')\n",
    "    ds_usv['longitude']=ds_usv.longitude.interpolate_na(dim='time')\n",
    "    xlat=ds_usv.latitude\n",
    "    xlon=ds_usv.longitude\n",
    "    dkm2 = abs(np.abs((((xlon[1:].data-xlon[0:-1].data)**2+(xlat[1:].data-xlat[0:-1].data)**2)**.5)*110.567*np.cos(np.pi*xlat[1:].data/180)))\n",
    "    dkm2=np.append(dkm2,dkm2[66238]) #add on last point\n",
    "    dkm3 = dkm2.cumsum()\n",
    "    ds_usv['dist_total']=xr.DataArray(dkm3,dims=('time'),coords={'time':ds_usv.time})\n",
    "    ds_usv['dist_between']=xr.DataArray(dkm2,dims=('time'),coords={'time':ds_usv.time})\n",
    "    if iusv==0:\n",
    "        ds = ds_usv\n",
    "    else:\n",
    "        ds = xr.concat([ds,ds_usv],dim='trajectory')\n",
    "ds_saildrone = ds.copy(deep=True)\n",
    "\n",
    "#read in temperature loggers\n",
    "ds_log = xr.open_mfdataset(data_dir+'*1_minute-v1.nc',combine='nested',concat_dim='trajectory')\n",
    "ds_log.close()\n",
    "\n",
    "\n",
    "ds_saildrone.wspd.attrs={'units':'m/s'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print out difference between two salinity sensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#i1,i2=2000,4000\n",
    "#plt.plot(ds_usv.tlmt[i1:i2],ds_usv.TEMP_AIR_MEAN[i1:i2])\n",
    "#tem=ds_usv3.sel(tlmt='2020-01-28')\n",
    "#tem2=tem.where(tem.tlmt.dt.hour==6)\n",
    "for i in range(45):\n",
    "    tt=np.datetime64('2020-01-17')+np.timedelta64(24*(i-1),'h')\n",
    "    tt2=tt+np.timedelta64(24,'h')\n",
    "    tem = ds_usv.sel(time=slice(tt,tt2))\n",
    "    if tem.wspd.mean().data<7.5:\n",
    "        plt.plot(tem.tlmt.dt.hour+tem.tlmt.dt.minute/60,tem.TEMP_SBE37_MEAN_DW,'.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv.TEMP_SBE37_MEAN_DW.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dmin,dmax=np.log(min(sp[2:1000])),np.log(max(sp[2:1000]))\n",
    "dmin,dmax=np.floor(100000*min(sp[2:1000]))/100000,np.ceil(max(sp[2:1000])/1000)*1000\n",
    "print(dmin,dmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def spec(data,var):\n",
    "    #calculate the periodogram spectrum spec_p\n",
    "    #calculate the slepian multitaper spectrum spec_m\n",
    "    ps_all,ps_all2=[],[]\n",
    "    for iusv in range(3):\n",
    "        ds_usv = data.isel(trajectory=iusv)\n",
    "        den = ds_usv[var].interpolate_na(dim='time')\n",
    "        den = den.where(np.isfinite(den),drop=True)\n",
    "        ds4_detrend_smooth = signal.detrend(den)\n",
    "        freq, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/1)  #fs = sampled at 1 min\n",
    "        ps_all.append(Pxx_den[0:10000])\n",
    "        Sk_complex, weights, eigenvalues = spectrum.pmtm(ds4_detrend_smooth, NW=3.5, k=4, show=False)\n",
    "        Sk = np.mean((abs(Sk_complex)**2) * weights.T, axis=0)\n",
    "        ps_all2.append(Sk[0:10000])\n",
    "    spec_p = np.mean(np.vstack(ps_all),axis=0)\n",
    "    spec_m = np.mean(np.vstack(ps_all2),axis=0)\n",
    "    return spec_p,spec_m,freq\n",
    "\n",
    "ds_saildrone\n",
    "\n",
    "list_var = ['TEMP_AIR_MEAN','TEMP_SBE37_MEAN','wspd','SAL_SBE37_MEAN']\n",
    "for var in list_var:\n",
    "    sp,sm,freq = spec(ds_saildrone,var)\n",
    "    dmin,dmax=np.floor(1000000*min(sp[2:1000]))/10000,np.ceil(max(sp[2:1000])/1000)*1000\n",
    "    plt.loglog([1/(60*6.15),1/(60*6.15)],[10e-5,10e3],'m')\n",
    "    plt.loglog([1/(60*8),1/(60*8)],[10e-5,10e3],'r')\n",
    "    plt.loglog([1/(60*12),1/(60*12)],[10e-5,10e3],'y')\n",
    "    plt.loglog([1/(60*24),1/(60*24)],[10e-5,10e3],'g')\n",
    "    plt.loglog(freq[0:1000], sp[0:1000],'b')\n",
    "    plt.loglog(freq[0:1000], sm[0:1000],'k',lw=2)\n",
    "    plt.ylim([dmin,dmax])\n",
    "    ifit=500\n",
    "    istart,iend=10,ifit\n",
    "    XX = np.log(freq[istart:iend])\n",
    "    YY = np.log(sp[istart:iend])\n",
    "    reg = LinearRegression().fit(XX.reshape(-1, 1), YY)\n",
    "    a = float(reg.coef_)\n",
    "    b = -1*float(reg.intercept_)\n",
    "    plt.loglog(freq[istart:iend], freq[istart:iend]**(a)/np.exp(b),'r') #test from fit\n",
    "    slp_str = 'slope = '+\"{:.1f}\".format(a)\n",
    "    plt.text(freq[istart+1],freq[istart]**(a)/np.exp(b)+500,slp_str,fontsize=16,color='r')  \n",
    "    \n",
    "    plt.xlabel('Frequency (min)')\n",
    "    #plt.xlabel('Wavelength (km)')\n",
    "    plt.ylabel('PSD (('+ds_usv[var].units+')$^2$ cpmin$^{-1}$]')\n",
    "    plt.savefig('F:/data/cruise_data/saildrone/2020_atomic/fig/fig_spectrum_'+var+'.png')\n",
    "    plt.clf()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(min(sp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE SPECTRUM sst TEMPERATURE, PEAKS AT 8, 12, 24 HRS\n",
    "data_all=[]\n",
    "for iusv in range(3):\n",
    "    ds_usv = ds_saildrone.isel(trajectory=iusv)\n",
    "    den = ds_usv.wspd.interpolate_na(dim='time')\n",
    "    den = den.where(np.isfinite(den),drop=True)\n",
    "    ds4_detrend_smooth = signal.detrend(den)\n",
    "    freq, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/1)  #fs = sampled at 1 min\n",
    "    freq2, Pxx_den2 = signal.welch(ds4_detrend_smooth,1/1,nperseg=1024*30)  #fs = sampled at 1 min\n",
    "    if iusv==0:\n",
    "        ps_all=Pxx_den[0:10000]\n",
    "        ps_all_welch=Pxx_den2[0:10000]\n",
    "    else:\n",
    "        ps_all = np.vstack([ps_all,Pxx_den[0:10000]])\n",
    "        ps_all_welch = np.vstack([ps_all_welch,Pxx_den2[0:10000]])    \n",
    "Pxx_den = np.mean(ps_all,axis=0)\n",
    "Pxx_den_welch = np.mean(ps_all_welch,axis=0)\n",
    "#plt.loglog([1/(60*8),1/(60*8)],[10e-5,10e3],'r')\n",
    "plt.loglog([1/(60*12),1/(60*12)],[10e-5,10e4],'y')\n",
    "plt.loglog([1/(60*24),1/(60*24)],[10e-5,10e4],'g')\n",
    "plt.loglog(freq[0:1000], Pxx_den[0:1000],'b')\n",
    "plt.ylim([10e-2,10e4])\n",
    "\n",
    "\n",
    "#linear regression to PSD\n",
    "ifit=500\n",
    "istart,iend=10,ifit\n",
    "XX = np.log(freq[istart:iend])\n",
    "YY = np.log(Pxx_den[istart:iend])\n",
    "reg = LinearRegression().fit(XX.reshape(-1, 1), YY)\n",
    "a = float(reg.coef_)\n",
    "b = -1*float(reg.intercept_)\n",
    "plt.loglog(freq[istart:iend], freq[istart:iend]**(a)/np.exp(b),'r') #test from fit\n",
    "slp_str = 'slope = '+\"{:.1f}\".format(a)\n",
    "plt.text(freq[istart+1],freq[istart]**(a)/np.exp(b)+500,slp_str,fontsize=16,color='r')\n",
    "#plt.ylim([10e-6,10e1])\n",
    "#plt.xlim([10e-4,10e-1])\n",
    "#plt.xticks(ticks=[.001,.01,.1,1],labels=['1000','100','10','1'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CALCULATE SPECTRUM sst TEMPERATURE, PEAKS AT 6.2, 12, 24 HRS\n",
    "data_all=[]\n",
    "for iusv in range(3):\n",
    "    ds_usv = ds_saildrone.isel(trajectory=iusv)\n",
    "    den = ds_usv.SAL_SBE37_MEAN.interpolate_na(dim='time')\n",
    "    den = den.where(np.isfinite(den),drop=True)\n",
    "    ds4_detrend_smooth = signal.detrend(den)\n",
    "    freq, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/1)  #fs = sampled at 1 min\n",
    "    freq2, Pxx_den2 = signal.welch(ds4_detrend_smooth,1/1,nperseg=1024*30)  #fs = sampled at 1 min\n",
    "    if iusv==0:\n",
    "        ps_all=Pxx_den[0:10000]\n",
    "        ps_all_welch=Pxx_den2[0:10000]\n",
    "    else:\n",
    "        ps_all = np.vstack([ps_all,Pxx_den[0:10000]])\n",
    "        ps_all_welch = np.vstack([ps_all_welch,Pxx_den2[0:10000]])    \n",
    "Pxx_den = np.mean(ps_all,axis=0)\n",
    "Pxx_den_welch = np.mean(ps_all_welch,axis=0)\n",
    "#plt.loglog([1/(60*8),1/(60*8)],[10e-5,10e3],'r')\n",
    "#plt.loglog([1/(60*12),1/(60*12)],[10e-5,10e3],'y')\n",
    "#plt.loglog([1/(60*24),1/(60*24)],[10e-5,10e3],'g')\n",
    "plt.loglog(freq[0:1000], Pxx_den[0:1000],'b')\n",
    "plt.ylim([10e-5,10e3])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SBE37 minus RBR\n",
    "dd=[]\n",
    "for iusv in range(3):\n",
    "    ds_usv=ds.isel(trajectory=iusv)\n",
    "    dif = ds_usv.SAL_SBE37_MEAN-ds_usv.SAL_RBR_MEAN\n",
    "    difm = dif.mean().data\n",
    "    difs = dif.std().data\n",
    "    print(ds_usv.trajectory.data,\"{:.2f}\".format(difm),\"{:.2f}\".format(difs),np.isfinite(dif).sum().data)\n",
    "    if iusv==0:\n",
    "        dd=ds_usv.SAL_SBE37_MEAN.data\n",
    "    else:\n",
    "        dd = np.concatenate([dd,ds_usv.SAL_SBE37_MEAN.data])\n",
    "print(\"{:.2f}\".format(np.nanmean(dd)),\"{:.2f}\".format(np.nanstd(dd)),np.isfinite(dd).sum())\n",
    "    \n",
    "# SBE37 minus RBR\n",
    "dd=[]\n",
    "for iusv in range(3):\n",
    "    ds_usv=ds.isel(trajectory=iusv)\n",
    "    dif = ds_usv.TEMP_SBE37_MEAN-ds_usv.TEMP_CTD_RBR_MEAN\n",
    "    difm = dif.mean().data\n",
    "    difs = dif.std().data\n",
    "    print(ds_usv.trajectory.data,\"{:.2f}\".format(difm),\"{:.2f}\".format(difs),np.isfinite(dif).sum().data)\n",
    "    if iusv==0:\n",
    "        dd=ds_usv.SAL_SBE37_MEAN.data\n",
    "    else:\n",
    "        dd = np.concatenate([dd,ds_usv.SAL_SBE37_MEAN.data])\n",
    "print(\"{:.2f}\".format(np.nanmean(dd)),\"{:.2f}\".format(np.nanstd(dd)),np.isfinite(dd).sum())\n",
    "    \n",
    "# SBE37 minus RBR\n",
    "dd=[]\n",
    "for iusv in range(3):\n",
    "    ds_usv=ds.isel(trajectory=iusv)\n",
    "    dif = ds_usv.CHLOR_WETLABS_MEAN-ds_usv.CHLOR_RBR_MEAN\n",
    "    difm = dif.mean().data\n",
    "    difs = dif.std().data\n",
    "    print(ds_usv.trajectory.data,\"{:.2f}\".format(difm),\"{:.2f}\".format(difs),np.isfinite(dif).sum().data)\n",
    "    if iusv==0:\n",
    "        dd=ds_usv.SAL_SBE37_MEAN.data\n",
    "    else:\n",
    "        dd = np.concatenate([dd,ds_usv.SAL_SBE37_MEAN.data])\n",
    "print(\"{:.2f}\".format(np.nanmean(dd)),\"{:.2f}\".format(np.nanstd(dd)),np.isfinite(dd).sum())\n",
    "\n",
    "# SBE37 minus RBR\n",
    "dd=[]\n",
    "for iusv in range(3):\n",
    "    ds_usv=ds.isel(trajectory=iusv)\n",
    "    dif = ds_usv.O2_CONC_SBE37_MEAN-ds_usv.O2_CONC_RBR_MEAN \n",
    "    difm = dif.mean().data\n",
    "    difs = dif.std().data\n",
    "    print(ds_usv.trajectory.data,\"{:.2f}\".format(difm),\"{:.2f}\".format(difs),np.isfinite(dif).sum().data)\n",
    "    if iusv==0:\n",
    "        dd=ds_usv.SAL_SBE37_MEAN.data\n",
    "    else:\n",
    "        dd = np.concatenate([dd,ds_usv.SAL_SBE37_MEAN.data])\n",
    "print(\"{:.2f}\".format(np.nanmean(dd)),\"{:.2f}\".format(np.nanstd(dd)),np.isfinite(dd).sum())\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "var,fvar=['SAL_SBE37_MEAN','TEMP_SBE37_MEAN','density_mean'],'sst_sal'\n",
    "#var,fvar=['TEMP_AIR_MEAN','TEMP_SBE37_MEAN','PAR_AIR_MEAN'],'air_wnd'\n",
    "#var,fvar=['TEMP_AIR_MEAN_DW','TEMP_SBE37_MEAN_DW','PAR_AIR_MEAN'],'air_wnd_DW'\n",
    "col=['tab:green','tab:red','tab:blue']\n",
    "for iusv in range(3):\n",
    "    fig,(ax0)= plt.subplots(1,1,figsize=(10,5))\n",
    "    ds_usv = ds.isel(trajectory=iusv)\n",
    "#    ax0.plot(ds_usv.time,ds_usv[var1],label=ds_usv.trajectory.data)\n",
    "    t1,t2='2020-01-17T00','2020-03-02T23'\n",
    "    \n",
    "    ivar=0\n",
    "    color,varin = col[ivar], var[ivar]\n",
    "    ax0.set_xlabel('time (s)')\n",
    "    ax0.set_ylabel(varin, color=color)\n",
    "    ax0.plot(ds_usv.time, ds_usv[varin], color=color)\n",
    "    ax0.tick_params(axis='y', labelcolor=color)\n",
    "    ax0.set_xlim([np.datetime64(t1),np.datetime64(t2)])\n",
    "    \n",
    "    ax2 = ax0.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    ivar=1\n",
    "    color,varin = col[ivar], var[ivar]\n",
    "    ax2.set_xlabel('time (s)')\n",
    "    ax2.set_ylabel(varin, color=color)\n",
    "    ax2.plot(ds_usv.time, ds_usv[varin], color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "    ax2 = ax0.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    ivar=1\n",
    "    color,varin = col[ivar], var[ivar]\n",
    "    ax2.set_xlabel('time (s)')\n",
    "    ax2.set_ylabel(varin, color=color)\n",
    "    ax2.plot(ds_usv.time, ds_usv[varin], color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax3 = ax0.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    ivar=2\n",
    "    color,varin = col[ivar], var[ivar]\n",
    "    ax3.set_xlabel('time (s)')\n",
    "    ax3.set_ylabel(varin, color=color)\n",
    "    ax3.plot(ds_usv.time, ds_usv[varin], color=color)\n",
    "    ax3.tick_params(axis='y', labelcolor=color)\n",
    "    ax3.spines[\"right\"].set_position((\"axes\", +1.1))\n",
    "\n",
    "    ax2a = ax0.twiny()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    # Decide the ticklabel position in the new x-axis,\n",
    "    # then convert them to the position in the old x-axis\n",
    "    #calculate new ticks\n",
    "    temdist = ds_usv.dist_total.data\n",
    "    print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "    tem = np.arange(math.ceil(ds_usv.dist_total[0].data/500)*500,math.floor(ds_usv.dist_total[-1].data/500)*500+600,1000)\n",
    "    ll=[]\n",
    "    for i in tem: #range(3750,4450,100):\n",
    "        ll.append(\"{:.0f}\".format(i))\n",
    "    isv=[]\n",
    "    for i in tem:\n",
    "        ii = np.argwhere((ds_usv.dist_total.data.astype(int))==i)\n",
    "        if len(ii)>0:\n",
    "            isv.append(int(ii.mean())/len(temdist))   \n",
    "    \n",
    "    new_tick_locations = isv\n",
    "    print(new_tick_locations)\n",
    "    ax2a.set_xticks(new_tick_locations)\n",
    "    ax2a.set_xticklabels(ll)\n",
    "    ax2a.set_xlabel('distance along track (km)')\n",
    "    plt.savefig(figs_dir+ fvar + '_timeseries_'+str(iusv)+'.png')\n",
    "#    plt.savefig(figs_dir+ '_timeseries_'+str(iusv)+'.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import math\n",
    "var,fvar=['SAL_SBE37_MEAN','TEMP_SBE37_MEAN','density_mean'],'sst_sal'\n",
    "#var,fvar=['TEMP_AIR_MEAN','TEMP_SBE37_MEAN','PAR_AIR_MEAN'],'air_wnd'\n",
    "#var,fvar=['TEMP_AIR_MEAN_DW','TEMP_SBE37_MEAN_DW','PAR_AIR_MEAN'],'air_wnd_DW0201'\n",
    "col=['tab:green','tab:red','tab:blue']\n",
    "for iusv in range(3):\n",
    "    fig,(ax0)= plt.subplots(1,1,figsize=(10,5))\n",
    "    ds_usv = ds.isel(trajectory=iusv)\n",
    "#    ax0.plot(ds_usv.time,ds_usv[var1],label=ds_usv.trajectory.data)\n",
    "    t1,t2='2020-02-16T00','2020-02-21T23'\n",
    "    \n",
    "    ivar=0\n",
    "    color,varin = col[ivar], var[ivar]\n",
    "    ax0.set_xlabel('time (s)')\n",
    "    ax0.set_ylabel(varin, color=color)\n",
    "    ax0.plot(ds_usv.time, ds_usv[varin], color=color)\n",
    "    ax0.tick_params(axis='y', labelcolor=color)\n",
    "    ax0.set_xlim([np.datetime64(t1),np.datetime64(t2)])\n",
    "    \n",
    "    ax2 = ax0.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    ivar=1\n",
    "    color,varin = col[ivar], var[ivar]\n",
    "    ax2.set_xlabel('time (s)')\n",
    "    ax2.set_ylabel(varin, color=color)\n",
    "    ax2.plot(ds_usv.time, ds_usv[varin], color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    fig.tight_layout()  # otherwise the right y-label is slightly clipped\n",
    "\n",
    "    ax2 = ax0.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    ivar=1\n",
    "    color,varin = col[ivar], var[ivar]\n",
    "    ax2.set_xlabel('time (s)')\n",
    "    ax2.set_ylabel(varin, color=color)\n",
    "    ax2.plot(ds_usv.time, ds_usv[varin], color=color)\n",
    "    ax2.tick_params(axis='y', labelcolor=color)\n",
    "\n",
    "    ax3 = ax0.twinx()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    ivar=2\n",
    "    color,varin = col[ivar], var[ivar]\n",
    "    ax3.set_xlabel('time (s)')\n",
    "    ax3.set_ylabel(varin, color=color)\n",
    "    ax3.plot(ds_usv.time, ds_usv[varin], color=color)\n",
    "    ax3.tick_params(axis='y', labelcolor=color)\n",
    "    ax3.spines[\"right\"].set_position((\"axes\", +1.1))\n",
    "\n",
    "    ax2a = ax0.twiny()  # instantiate a second axes that shares the same x-axis\n",
    "\n",
    "    # Decide the ticklabel position in the new x-axis,\n",
    "    # then convert them to the position in the old x-axis\n",
    "    #calculate new ticks\n",
    "    temdist = ds_usv.dist_total.data\n",
    "    print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "    tem = np.arange(math.ceil(ds_usv.dist_total[0].data/500)*500,math.floor(ds_usv.dist_total[-1].data/500)*500+600,1000)\n",
    "    ll=[]\n",
    "    for i in tem: #range(3750,4450,100):\n",
    "        ll.append(\"{:.0f}\".format(i))\n",
    "    isv=[]\n",
    "    for i in tem:\n",
    "        ii = np.argwhere((ds_usv.dist_total.data.astype(int))==i)\n",
    "        if len(ii)>0:\n",
    "            isv.append(int(ii.mean())/len(temdist))   \n",
    "    \n",
    "    new_tick_locations = isv\n",
    "    print(new_tick_locations)\n",
    "    ax2a.set_xticks(new_tick_locations)\n",
    "    ax2a.set_xticklabels(ll)\n",
    "    ax2a.set_xlabel('distance along track (km)')\n",
    "    plt.savefig(figs_dir+ fvar + '_timeseries_'+str(iusv)+'.png')\n",
    "#    plt.savefig(figs_dir+ '_timeseries_'+str(iusv)+'.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv=ds.isel(trajectory=0)\n",
    "print(ds_usv.time[0].data,ds_usv.time[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# read in satellite data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,t2=dt.datetime(2020,1,17),dt.datetime(2020,3,7)\n",
    "fnames=[]\n",
    "for i in range(46):\n",
    "    t=t1+dt.timedelta(days=i)\n",
    "    tdir = t-dt.timedelta(days=4)\n",
    "    sdoy = str(tdir.timetuple().tm_yday).zfill(3)\n",
    "    smon = str(t.month).zfill(2)\n",
    "    sdy  = str(t.day).zfill(2)\n",
    "    fname = 'Z:/SalinityDensity/smap/L3/JPL/V4.3/8day_running/2020/' + sdoy + '/SMAP_L3_SSS_2020'+smon+sdy+'_8DAYS_V4.3.nc'\n",
    "    fnames.append(fname)\n",
    "tem = xr.open_mfdataset(fnames,combine='nested',concat_dim='time')\n",
    "tem = tem.rename({'latitude':'lat','longitude':'lon'}).sel(lon=slice(-64,-46),lat=slice(16,4))\n",
    "ds_jpl = tem.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,t2=dt.datetime(2020,1,17),dt.datetime(2020,3,7)\n",
    "fnames=[]\n",
    "for i in range(46):\n",
    "    t=t1+dt.timedelta(days=i)\n",
    "    tdir = t-dt.timedelta(days=4)\n",
    "    sdoy = str(tdir.timetuple().tm_yday).zfill(3)\n",
    "    sdoy2 = str(t.timetuple().tm_yday).zfill(3)\n",
    "            #\\\\White_home_pc\\f\\data\\sat_data\\smap\\SSS\\L3\\RSS\\V4\\8day_running\\SCI\\2020\n",
    "    fname = '//white_home_pc/f/data/sat_data/smap/SSS/L3/RSS/V4/8day_running/SCI/2020/' + sdoy + '/RSS_smap_SSS_L3_8day_running_2020_'+sdoy2+'_FNL_v04.0.nc'\n",
    "#    fname = 'Z:/SalinityDensity/smap/L3/RSS/V4/8day_running/SCI/2020/' + sdoy + '/RSS_smap_SSS_L3_8day_running_2020_'+sdoy2+'_FNL_v04.0.nc'\n",
    "    fnames.append(fname)\n",
    "tem = xr.open_mfdataset(fnames,combine='nested',concat_dim='time')\n",
    "tem.coords['lon'] = (tem.coords['lon'] + 180) % 360 - 180\n",
    "tem = tem.sortby(tem.lon)\n",
    "tem = tem.sel(lon=slice(-64,-46),lat=slice(4,16))\n",
    "ds_rss = tem.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_fig(ds_sat,ds,var,text1,text2,fout,date_str):\n",
    "    ds_sat = ds_sat.sel(time=date_str)\n",
    "    fig = plt.figure(figsize=(8,6))\n",
    "    ax = plt.axes(projection = ccrs.PlateCarree())  # create a set of axes with Mercator projection\n",
    "    im=ax.pcolormesh(ds_sat.lon,ds_sat.lat,ds_sat[var],vmin=34,vmax=36.5,transform=ccrs.PlateCarree(),cmap='viridis')\n",
    "    for i in range(3):\n",
    "        ds2 = ds.isel(trajectory=i)\n",
    "        ax.scatter(ds2.longitude,ds2.latitude,c=ds2.SAL_SBE37_MEAN,vmin=34,vmax=36.5,\n",
    "                      s=.15,transform=ccrs.PlateCarree(),label=ds2.trajectory.data,cmap='viridis')\n",
    "        ds2a = ds.isel(trajectory=i).sel(time=date_str)\n",
    "        ax.plot(ds2a.longitude,ds2a.latitude,'.',transform=ccrs.PlateCarree(),color='w')\n",
    "\n",
    "    ax.coastlines(resolution='10m')                \n",
    "    ax.set_extent([-64,-46,4,16])\n",
    "    bx1 = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                      linewidth=0, color='grey', alpha=0.5, linestyle='--')\n",
    "    bx1.xlabels_top = False; bx1.ylabels_left = True\n",
    "    bx1.ylabels_right = False; bx1.xlines = False\n",
    "    bx1.xlocator = mticker.FixedLocator([-60,-55,-50,-45])\n",
    "    bx1.xformatter = LONGITUDE_FORMATTER; bx1.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "    #ax.legend()\n",
    "    ax.text(-63.5,7.5,'South America',fontsize=14)\n",
    "    ax.text(-63.5,5,text1,fontsize=14)\n",
    "    ax.text(-63.5,4.3,text2,fontsize=14)\n",
    "    cax = fig.add_axes([0.5, 0.8, 0.37, 0.02])\n",
    "    cbar = fig.colorbar(im,cax=cax, orientation='horizontal')\n",
    "    cbar.set_label('Salinity (psu)')\n",
    "    fig.savefig(figs_dir+fout)     \n",
    "\n",
    "date_str = '2020-01-30T1200'\n",
    "text2='7 Feb 2020 8-day Average'\n",
    "\n",
    "text1='RSS SMAP Salinity v4'\n",
    "map_fig(ds_rss,ds,'sss_smap',text1,text2,'map_sss_rss_smap.png',date_str)\n",
    "\n",
    "text1='RSS SMAP Salinity v4 - 40 km'\n",
    "map_fig(ds_rss,ds,'sss_smap_40km',text1,text2,'map_sss_rss_smap40km.png',date_str)\n",
    "\n",
    "text1='JPL SMAP Salinity v4.3'\n",
    "map_fig(ds_jpl,ds,'smap_sss',text1,text2,'map_sss_jpl_smap.png',date_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem = ds.sel(time='2020-01-30')\n",
    "plt.plot(ds.longitude[0,:],ds.latitude[0,:])\n",
    "plt.plot(tem.longitude[0,:],tem.latitude[0,:],'r.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_stats(tstr,ds_sat2,var,ds_in,varsst,varden):\n",
    "    import xarray\n",
    "    import seawater as sw\n",
    "    print('******'+tstr+'*******')\n",
    "    for iusv in range(3):\n",
    "        ds_usv = ds_in.isel(trajectory=iusv)\n",
    "        tem = ds_sat2.interp(time=ds_usv.time,lat=ds_usv.latitude,lon=ds_usv.longitude)\n",
    "        dif = tem[var]-ds_usv.SAL_SBE37_MEAN\n",
    "        difm = dif.mean().data\n",
    "        difs = dif.std().data\n",
    "        print(iusv,\"{:.2f}\".format(difm),\"{:.2f}\".format(difs),np.isfinite(dif).sum().data)\n",
    "        tem2=sw.dens0(tem[var],tem[varsst]-273.15) #ds.TEMP_SBE37_MEAN[iusv,:])\n",
    "        tem[varden]=xr.DataArray(tem2.data,dims=('time'),coords={'time':ds_usv.time})\n",
    "        tem['dist_total']=xr.DataArray(ds_usv.dist_total.data,dims=('time'),coords={'time':ds_usv.time})\n",
    "        if iusv==0:\n",
    "            ds_out = tem\n",
    "        else:\n",
    "            ds_out = xr.concat([ds_out,tem],dim='trajectory')\n",
    "    return ds_out\n",
    "\n",
    "ds_rss_usv = print_stats('RSS',ds_rss,'sss_smap',ds,'surtep','density_mean')\n",
    "ds_rss_usv40 = print_stats('RSS40km',ds_rss,'sss_smap_40km',ds,'surtep','density_mean')\n",
    "ds_jpl_usv = print_stats('JPL',ds_jpl,'smap_sss',ds,'anc_sst','density_mean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# print eddy TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iusv=0\n",
    "ds_usv = ds.isel(trajectory=iusv).sel(time=slice('2020-02-15T09','2020-02-21T0029'))\n",
    "print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "ll=[]\n",
    "for i in range(3750,4450,100):\n",
    "    ll.append(\"{:.0f}\".format(i))\n",
    "print(ll)\n",
    "fig,(ax0)= plt.subplots(1,1,figsize=(15,6))\n",
    "t1,t2='2020-02-15T09','2020-02-21T00'\n",
    "for iusv in range(3):\n",
    "    ds_usv = ds.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "    ax0.plot(ds_usv.time,ds_usv.SAL_SBE37_MEAN,label=ds_usv.trajectory.data)\n",
    "ds_usv = ds_jpl_usv.isel(trajectory=0).sel(time=slice(t1,t2))\n",
    "ax0.plot(ds_usv.time,ds_usv.smap_sss,label='JPL')\n",
    "ds_usv = ds_rss_usv.isel(trajectory=0).sel(time=slice(t1,t2))\n",
    "ax0.plot(ds_usv.time,ds_usv.sss_smap,label='RSS')\n",
    "ax0.plot(ds_usv.time,ds_usv.sss_smap_40km,label='RSS 40 km')\n",
    "ax0.legend()\n",
    "ax0.set_ylabel('Salinity (psu)')\n",
    "ax0.set_xlabel('Date')\n",
    "ax0.set_xlim([np.datetime64(t1),np.datetime64(t2)])\n",
    "\n",
    "pos = ax0.get_position()\n",
    "pos.y0 = pos.y0+.04       # for example 0.2, choose your value\n",
    "ax0.set_position(pos)\n",
    "#handles, labels = ax.get_legend_handles_labels()\n",
    "#ax0.get_xticklabels(), ha=\"right\", rotation=45)\n",
    "ax2 = ax0.twiny()\n",
    "# Add some extra space for the second axis at the bottom\n",
    "#fig.subplots_adjust(bottom=0.2)\n",
    "# Move twinned axis ticks and label from top to bottom\n",
    "ax2.xaxis.set_ticks_position(\"bottom\")\n",
    "ax2.xaxis.set_label_position(\"bottom\")\n",
    "# Offset the twin axis below the host\n",
    "ax2.spines[\"bottom\"].set_position((\"axes\", -0.06))\n",
    "ax1Ticks = ax0.get_xticks()   \n",
    "ax2Ticks = ax1Ticks\n",
    "new_tick_locations = np.arange(0,1,0.166)\n",
    "print(new_tick_locations)\n",
    "ax2.set_xticks(new_tick_locations)\n",
    "ax2.set_xticklabels(ll)\n",
    "ax2.set_xlabel('distance along track (km)')\n",
    "#labels = [item.get_text() for item in ax0.get_xticklabels()]\n",
    "#ax0.set_xticklabels(labels,rotation=45) \n",
    "plt.savefig(figs_dir+'timeseries_eddy.png')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "freq_usv,freq2_usv,Pxx_den_usv,Pxx_den_welch_usv = spectrum(ds)\n",
    "freq_jpl,freq2_jpl,Pxx_den_jpl,Pxx_den_welch_jpl = spectrum(ds_jpl_usv)\n",
    "freq_rss,freq2_rss,Pxx_den_rss,Pxx_den_welch_rss = spectrum(ds_rss_usv)\n",
    "freq_rss4,freq2_rss4,Pxx_den_rss4,Pxx_den_welch_rss4 = spectrum(ds_rss_usv40)\n",
    "\n",
    "ddn_usv = cal_pdf(ds)\n",
    "ddn_jpl = cal_pdf(ds_jpl_usv)\n",
    "ddn_rss = cal_pdf(ds_rss_usv)\n",
    "ddn_rss4 = cal_pdf(ds_rss_usv40)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "psd_fig(freq_usv,ddn_usv,Pxx_den_usv,'Saildrone','PSD_den_grad_usv.png',300)\n",
    "psd_fig(freq_jpl,ddn_jpl,Pxx_den_jpl,'JPL','PSD_den_grad_jpl.png',45)\n",
    "psd_fig(freq_rss,ddn_rss,Pxx_den_rss,'RSS','PSD_den_grad_rss_.png',45)\n",
    "psd_fig(freq_rss4,ddn_rss4,Pxx_den_rss4,'RSS 40km','PSD_den_grad_rss_40km.png',75)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1/freq_usv[3],1/freq_usv[300])\n",
    "#calculate max gradient\n",
    "data_in = ds_saildrone\n",
    "#make arrays for sampling at different length scales\n",
    "length_scale = np.arange(.1,200,1)\n",
    "for iusv in range(3):\n",
    "    ds_usv = data_in.isel(trajectory=iusv)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)  #add dist traveled coordinate\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})                  #swap from time to distance traveled\n",
    "    for ilen2,len2 in enumerate(length_scale):\n",
    "        if ilen2>3:\n",
    "            continue\n",
    "        dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],len2)\n",
    "        ds4 = ds3.interp(dist_total=dist_interp)       \n",
    "        den_grad =  np.abs(np.gradient(ds4.density_mean)/len2)\n",
    "        print(len2,max(den_grad))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test spatial resolution\n",
    "ds_saildrone['sss_jpl']=ds_jpl_usv.smap_sss\n",
    "ds_saildrone['sss_rss']=ds_rss_usv.sss_smap\n",
    "ds_saildrone['sss_rss4']=ds_rss_usv.sss_smap_40km\n",
    "length_scale = np.arange(10,500,10)\n",
    "for ilen2,len2 in enumerate(length_scale):\n",
    "    iusv=0\n",
    "    ds_usv = data_in.isel(trajectory=iusv)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)  #add dist traveled coordinate\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})                  #swap from time to distance traveled\n",
    "    ds4 = scipy.ndimage.filters.gaussian_filter1d(ds3.SAL_SBE37_MEAN.data, sigma=len2)\n",
    "#    dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],len2)\n",
    "#    ds4 = ds3.interp(dist_total=dist_interp)       \n",
    "    rdif1 = ds4 - ds3.sss_jpl #.data\n",
    "    rdif2 = ds4 - ds3.sss_rss\n",
    "    rdif3 = ds4 - ds3.sss_rss4\n",
    "    print(len2,rdif1.std().data,rdif2.std().data,rdif3.std().data)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv = data_in.isel(trajectory=iusv)\n",
    "ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)  #add dist traveled coordinate\n",
    "ds3 = ds2.swap_dims({'time':'dist_total'})                  #swap from time to distance traveled\n",
    "ds4 = scipy.ndimage.filters.gaussian_filter1d(ds3.SAL_SBE37_MEAN.data, sigma=200)\n",
    "m1= ds3.sss_rss4-ds3.sss_rss4.mean()\n",
    "print(np.mean(ds4))\n",
    "m2 = ds4-np.nanmean(ds4)\n",
    "m1 = m1[:50000]\n",
    "m2 = m2[:50000]\n",
    "plt.plot(m1)\n",
    "plt.plot(m2)\n",
    "print(np.std(m1-m2).data)\n",
    "#plt.plot(ds3.sss_rss4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime as dt\n",
    "t1,t2=dt.datetime(2020,1,17),dt.datetime(2020,3,7)\n",
    "fnames=[]\n",
    "for i in range(46):\n",
    "    t=t1+dt.timedelta(days=i)\n",
    "    tdir = t-dt.timedelta(days=4)\n",
    "    sdoy = str(tdir.timetuple().tm_yday).zfill(3)\n",
    "    smon = str(t.month).zfill(2)\n",
    "    sdy  = str(t.day).zfill(2)\n",
    "    fname = 'Z:/SalinityDensity/smap/L3/JPL/V4.3/8day_running/2020/' + sdoy + '/SMAP_L3_SSS_2020'+smon+sdy+'_8DAYS_V4.3.nc'\n",
    "    fnames.append(fname)\n",
    "tem = xr.open_mfdataset(fnames,combine='nested',concat_dim='time')\n",
    "tem = tem.rename({'latitude':'lat','longitude':'lon'}).sel(lon=slice(-64,-46),lat=slice(16,4))\n",
    "ds_jpl = tem.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cal PSD\n",
    "fig = plt.figure(figsize=(14,14))\n",
    "#Pxx_den = np.mean(ps_all_usv,axis=0)\n",
    "#f, Pxx_den = signal.periodogram(Pxx_den,1/.080)  #fs = sampled at .08km or 80m\n",
    "istart,iend=5,5550\n",
    "plt.loglog(freq_usv[istart:iend], Pxx_den_usv[istart:iend],'k',label='USV')\n",
    "plt.loglog(freq_jpl[istart:iend], Pxx_den_jpl[istart:iend],'g',label='JPL')\n",
    "plt.loglog(freq_rss[istart:iend], Pxx_den_rss[istart:iend],'r',label='RSS')\n",
    "plt.loglog(freq_rss4[istart:iend], Pxx_den_rss4[istart:iend],'m',label='RSS 40km')\n",
    "\n",
    "#linear regression to PSD\n",
    "Pxx_den = np.mean(ps_all_usv,axis=0)\n",
    "istart,iend=10,300\n",
    "XX,YY = np.log(freq_usv[istart:iend]),np.log(Pxx_den[istart:iend])\n",
    "reg = LinearRegression().fit(XX.reshape(-1, 1), YY)\n",
    "a,b = float(reg.coef_), -1*float(reg.intercept_)\n",
    "plt.loglog(f[istart:iend], f[istart:iend]**(a)/np.exp(b),'c',linewidth=2) #test from fit\n",
    "slp_str = 'slope = '+\"{:.1f}\".format(a)\n",
    "plt.text(.01,10,slp_str,fontsize=20,color='c')\n",
    "\n",
    "plt.ylim([10e-5,10e1])\n",
    "plt.xlim([.0015,.2])\n",
    "plt.legend(fontsize=20)\n",
    "\n",
    "#plt.text(.001,20,'(b)',fontsize=16,color='k')\n",
    "plt.xlabel('Wavelength (km)',fontsize=20)\n",
    "#plt.xlabel('Wavenumber (cpkm)',fontsize=20)\n",
    "plt.ylabel('PSD ((kg m$^{-3}$)$^2$ cpkm$^{-1}$]',fontsize=20)\n",
    "plt.xticks(ticks=[.01,.1],labels=['100','10'],fontsize=20)\n",
    "plt.yticks(fontsize=20)\n",
    "plt.grid()\n",
    "plt.savefig(figs_dir+'all_spectrusm_only.png')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./../../flux/')\n",
    "from coare3 import coare3\n",
    "from gravity_constant import grv\n",
    "jcool = 1 #ocean bulk temperature\n",
    "WS_height = 4.5  #saildrone height obs\n",
    "Ta_height = 2.3\n",
    "Rs_mean = 312   #from eyeballing 1037 data\n",
    "Rl_mean = 300  #from eyeballing 1037 data\n",
    "\n",
    "\n",
    "jcool = 1 # implement cool calculation skin switch, 0=no, 1=yes\n",
    "\n",
    "ds['sensible_heat_flux_v3']=ds.TEMP_AIR_MEAN.copy(deep=True)\n",
    "ds['latent_heat_flux_v3']=ds.TEMP_AIR_MEAN.copy(deep=True)\n",
    "ds['cool_skin_v3']=ds.TEMP_AIR_MEAN.copy(deep=True)\n",
    "ds['skin_thickness_v3']=ds.TEMP_AIR_MEAN.copy(deep=True)\n",
    "for i in range(3):\n",
    "    ds2 = ds.isel(trajectory=i)\n",
    "    \n",
    "    inputs = {'u':ds2.wspd,\n",
    "              't':ds2.TEMP_AIR_MEAN,\n",
    "              'rh':ds2.RH_MEAN,\n",
    "              'P':ds2.BARO_PRES_MEAN,\n",
    "              'ts':ds2.TEMP_SBE37_MEAN,\n",
    "              'lat':ds2.latitude,\n",
    "             'zt':Ta_height,\n",
    "             'zu':WS_height,\n",
    "             'Rl':Rl_mean,\n",
    "             'Rs':Rs_mean}\n",
    "    res = coare3(inputs)\n",
    "    ds2['sensible_heat_flux_v3']=xr.DataArray(res['hsb'][0,:].data,coords=[ds2.time],dims=['time'],\n",
    "                                           attrs={'long_name':'sensible heat flux into ocean','units':'W/m^2'})\n",
    "    ds2['latent_heat_flux_v3']=xr.DataArray(res['hlb'][0,:].data,coords=[ds2.time],dims=['time'],\n",
    "                                           attrs={'long_name':'latent heat flux into ocean','units':'W/m^2'})\n",
    "    ds2['cool_skin_v3']=xr.DataArray(res['dter'][0,:].data,coords=[ds2.time],dims=['time'],\n",
    "                                           attrs={'long_name':'cool-skin temperature depression','units':'degC'})\n",
    "    ds2['skin_thickness_v3']=xr.DataArray(res['tkt'][0,:].data,coords=[ds2.time],dims=['time'],\n",
    "                                           attrs={'long_name':'cool-skin thickness','units':'m'})\n",
    "    if i==0:\n",
    "        ds3=ds2\n",
    "    else:\n",
    "        ds3=xr.concat([ds3,ds2],dim='trajectory')\n",
    "ds['sensible_heat_flux_v3']=ds3.sensible_heat_flux_v3.copy(deep=True)\n",
    "ds['latent_heat_flux_v3']=ds3.latent_heat_flux_v3.copy(deep=True)\n",
    "ds['cool_skin_v3']=ds3.cool_skin_v3.copy(deep=True)\n",
    "ds['skin_thickness_v3']=ds3.skin_thickness_v3.copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hist air sea temp diff\n",
    "for iusv in range(3):\n",
    "    ds_usv = ds.isel(trajectory=iusv)\n",
    "    dif = ds_usv.TEMP_AIR_MEAN-ds_usv.TEMP_SBE37_MEAN\n",
    "    hist, bin_edges = np.histogram(dif,bins=np.arange(-3.5,4,0.01))\n",
    "    if iusv==0:\n",
    "        hist2 = hist\n",
    "    else:\n",
    "        hist2+=hist\n",
    "    dif = ds_usv.TEMP_AIR_MEAN-(ds_usv.TEMP_SBE37_MEAN-ds_usv.cool_skin_v3)\n",
    "    hist, bin_edges = np.histogram(dif,bins=np.arange(-3.5,4,0.01))\n",
    "    if iusv==0:\n",
    "        hist4 = hist\n",
    "    else:\n",
    "        hist4+=hist\n",
    "hist2=hist2/sum(hist2)\n",
    "hist4=hist4/sum(hist4)\n",
    "plt.plot(bin_edges[:-1],hist2,label='Tair-Tdepth')\n",
    "plt.plot(bin_edges[:-1],hist4,'r',label='Tair-Tskin')\n",
    "print((ds_usv.TEMP_AIR_MEAN-ds_usv.TEMP_SBE37_MEAN).mean().data,(ds_usv.TEMP_AIR_MEAN-(ds_usv.TEMP_SBE37_MEAN-ds_usv.cool_skin_v3)).mean().data)\n",
    "plt.legend()\n",
    "plt.savefig(figs_dir+'hist_TairMinusTbulk.png')  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,6))\n",
    "ax = plt.axes(projection = ccrs.PlateCarree())  # create a set of axes with Mercator projection\n",
    "#im=ax.pcolormesh(ds_sat.lon,ds_sat.lat,ds_sat[var],vmin=34,vmax=36.5,transform=ccrs.PlateCarree(),cmap='viridis')\n",
    "for i in range(3):\n",
    "    ds2 = ds.isel(trajectory=i)\n",
    "    ax.scatter(ds2.longitude,ds2.latitude,c=ds2.TEMP_AIR_MEAN-ds2.TEMP_SBE37_MEAN,vmin=-1,vmax=1,\n",
    "                  s=.15,transform=ccrs.PlateCarree(),label=ds2.trajectory.data,cmap='seismic')\n",
    "\n",
    "ax.coastlines(resolution='10m')                \n",
    "ax.set_extent([-64,-46,4,16])\n",
    "bx1 = ax.gridlines(crs=ccrs.PlateCarree(), draw_labels=True,\n",
    "                  linewidth=0, color='grey', alpha=0.5, linestyle='--')\n",
    "bx1.xlabels_top = False; bx1.ylabels_left = True\n",
    "bx1.ylabels_right = False; bx1.xlines = False\n",
    "bx1.xlocator = mticker.FixedLocator([-60,-55,-50,-45])\n",
    "bx1.xformatter = LONGITUDE_FORMATTER; bx1.yformatter = LATITUDE_FORMATTER\n",
    "\n",
    "#ax.legend()\n",
    "ax.text(-63.5,7.5,'South America',fontsize=14)\n",
    "#ax.text(-63.5,5,text1,fontsize=14)\n",
    "#ax.text(-63.5,4.3,text2,fontsize=14)\n",
    "cax = fig.add_axes([0.5, 0.8, 0.37, 0.02])\n",
    "cbar = fig.colorbar(im,cax=cax, orientation='horizontal')\n",
    "cbar.set_label('Salinity (psu)')\n",
    "#fig.savefig(figs_dir+fout)     \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds2.cool_skin_v3.plot()\n",
    "#ds2.skin_thickness_v3[0:10000].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iusv in range(3):\n",
    "    plt.scatter(ds_usv.SAL_SBE37_MEAN,ds_usv.TEMP_SBE37_MEAN,c=ds_usv.density_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds_in,ds_rss_in,ds_jpl_in,str2,offset):\n",
    "    import math\n",
    "    iusv=0\n",
    "    ds_usv = ds_in.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "    print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "    ll=[]\n",
    "    for i in range(3750,4450,100):\n",
    "        ll.append(\"{:.0f}\".format(i))\n",
    "    print(ll)\n",
    "    fig,(ax0)= plt.subplots(1,1,figsize=(15,6))\n",
    "    for iusv in range(1):\n",
    "        ds_usv = ds.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "        ax0.plot(ds_usv.time,ds_usv[var1],label=ds_usv.trajectory.data)\n",
    "    ds_usv = ds_jpl_in.isel(trajectory=0).sel(time=slice(t1,t2))\n",
    "    ax0.plot(ds_usv.time,ds_usv[var2]+offset,label='JPL')\n",
    "    ds_usv = ds_rss_in.isel(trajectory=0).sel(time=slice(t1,t2))\n",
    "    ax0.plot(ds_usv.time,ds_usv[var3]+offset,label='RSS')\n",
    "    ax0.plot(ds_usv.time,ds_usv[var4]+offset,label='RSS 40 km')\n",
    "    ax0.legend()\n",
    "    ax0.set_ylabel(ystr)\n",
    "    ax0.set_xlabel('Date')\n",
    "#    ax0.set_xlim([np.datetime64(t1),np.datetime64(t2)])\n",
    "    ax0.set_xlim([t1,t2])\n",
    "\n",
    "    pos = ax0.get_position()\n",
    "    #pos.y0 = pos.y0+.04       # for example 0.2, choose your value\n",
    "    ax0.set_position(pos)\n",
    "    ax2 = ax0.twiny()\n",
    "    # Move twinned axis ticks and label from top to bottom\n",
    "    ax2.xaxis.set_ticks_position(\"top\")\n",
    "    ax2.xaxis.set_label_position(\"top\")\n",
    "    # Offset the twin axis below the host\n",
    "    #ax2.spines[\"bottom\"].set_position((\"axes\", -0.06))\n",
    "    ax1Ticks = ax0.get_xticks()   \n",
    "    ax2Ticks = ax1Ticks\n",
    "    \n",
    "    #calculate new ticks\n",
    "    temdist = ds_usv.dist_total.data\n",
    "    print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "    tem = np.arange(math.ceil(ds_usv.dist_total[0].data/50)*50,math.floor(ds_usv.dist_total[-1].data/50)*50+60,100)\n",
    "    ll=[]\n",
    "    for i in tem: #range(3750,4450,100):\n",
    "        ll.append(\"{:.0f}\".format(i))\n",
    "    isv=[]\n",
    "    for i in tem:\n",
    "        ii = np.argwhere((ds_usv.dist_total.data.astype(int))==i)\n",
    "        if len(ii)>0:\n",
    "            isv.append(int(ii.mean())/len(temdist))   \n",
    "    \n",
    "    new_tick_locations = isv\n",
    "    print(new_tick_locations)\n",
    "    ax2.set_xticks(new_tick_locations)\n",
    "    ax2.set_xticklabels(ll)\n",
    "    ax2.set_xlabel('distance along track (km)')\n",
    "    plt.savefig(figs_dir+ 'timeseries_'+str(t1)+'eddy'+str2+'.png')\n",
    "\n",
    "t1,t2 = np.datetime64('2020-02-15T09'),np.datetime64('2020-02-21T00')\n",
    "offset=0\n",
    "var1,var2,var3,var4,ystr= 'SAL_SBE37_MEAN','smap_sss','sss_smap','sss_smap_40km','Salinity (psu)'\n",
    "ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds,ds_rss_usv,ds_jpl_usv,'salinity',offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,t2 = np.datetime64('2020-02-15T09'),np.datetime64('2020-02-21T00')\n",
    "var1,var2,var3,var4,ystr= 'SAL_SBE37_MEAN','smap_sss','sss_smap','sss_smap_40km','Salinity (psu)'\n",
    "dy1 = ds.time[0]\n",
    "offset=0\n",
    "for i in range(12):\n",
    "    t1 = np.datetime64('2020-01-20')+np.timedelta64((i-1)*5,'D')\n",
    "    t2 = t1+np.timedelta64(5,'D')\n",
    "    ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds,ds_rss_usv,ds_jpl_usv,'salinity',offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,t2 = np.datetime64('2020-02-15T09'),np.datetime64('2020-02-21T00')\n",
    "var1,var2,var3,var4,ystr= 'SAL_SBE37_MEAN','smap_sss','sss_smap','sss_smap_40km','Salinity (psu)'\n",
    "dy1 = ds.time[0]\n",
    "offset=0\n",
    "for i in range(12):\n",
    "    t1 = np.datetime64('2020-01-20')+np.timedelta64((i-1)*5,'D')\n",
    "    t2 = t1+np.timedelta64(5,'D')\n",
    "    ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds,ds_rss_usv,ds_jpl_usv,'salinity',offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t1,t2 = np.datetime64('2020-02-15T09'),np.datetime64('2020-02-21T00')\n",
    "var1,var2,var3,var4,ystr= 'TEMP_SBE37_MEAN','anc_sst','surtep','surtep','SST (K)'\n",
    "dy1 = ds.time[0]\n",
    "offset=-273.15\n",
    "for i in range(12):\n",
    "    t1 = np.datetime64('2020-01-20')+np.timedelta64((i-1)*5,'D')\n",
    "    t2 = t1+np.timedelta64(5,'D')\n",
    "    ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds,ds_rss_usv,ds_jpl_usv,'sst',offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(1):\n",
    "    t1 = np.datetime64('2020-01-20')+np.timedelta64((i-1)*5,'D')\n",
    "    t2 = t1+np.timedelta64(5,'D')\n",
    "    tem = ds_log.isel(trajectory=0)\n",
    "    tem = tem.swap_dims({'obs':'time'}).sel(time=slice(t1,t2))\n",
    "    plt.plot(tem.time,tem.sea_water_temperature_00_mean-tem.sea_water_temperature_03_mean)\n",
    "    plt.plot(tem.time,tem.sea_water_temperature_01_mean-tem.sea_water_temperature_03_mean)\n",
    "    plt.plot(tem.time,tem.sea_water_temperature_02_mean-tem.sea_water_temperature_03_mean)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    tem = ds_log.isel(trajectory=0)\n",
    "    tem2 = ds.isel(trajectory=0).sel(time=slice('2020-03-01','2020-03-10'))\n",
    "    tem = tem.swap_dims({'obs':'time'})\n",
    "#    plt.plot(tem.time,tem.sea_water_temperature_00_mean-tem.sea_water_temperature_03_mean)\n",
    "#    plt.plot(ds.time,tem2.TEMP_SBE37_MEAN-tem.sea_water_temperature_03_mean)\n",
    "#    plt.plot(ds.time,tem2.TEMP_SBE37_MEAN)\n",
    "    plt.plot(tem2.time,tem2.wspd)\n",
    "#    plt.plot(tem.time,tem.sea_water_temperature_01_mean-tem.sea_water_temperature_03_mean)\n",
    "#    plt.plot(tem.time,tem.sea_water_temperature_02_mean-tem.sea_water_temperature_03_mean)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check what the min/max/mean distance travelled between 1 min obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iusv in range(3):\n",
    "    print(ds.dist_between[iusv,:].min().data,ds.dist_between[iusv,:].max().data,ds.dist_between[iusv,:].mean().data)\n",
    "#ave distance is 0.08 km = 80 m "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make an evenly sampled timeseries\n",
    "- Swap the coordinates from time to distance_total\n",
    "- interp along evenly sampled distance total, 80m (0.08km)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv = ds.isel(trajectory=0)\n",
    "ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08)\n",
    "ds4 = ds3.interp(dist_total=dist_interp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds2.time,ds3.density_mean)\n",
    "plt.plot(ds_usv.time,ds_usv.density_mean)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# detrend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "den = ds4.density_mean.interpolate_na(dim='dist_total')\n",
    "ds4_detrend = signal.detrend(den)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(ds4.density_mean)\n",
    "#plt.plot(den)\n",
    "plt.plot(ds4_detrend)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# , smooth using 2km gaussian filter then power density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ds4_detrend_smooth = scipy.ndimage.filters.gaussian_filter1d(ds4_detrend, sigma=25)\n",
    "plt.plot(ds4_detrend_smooth[5000:7000])\n",
    "plt.plot(ds4_detrend[5000:7000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/.080)  #fs = sampled at .08km or 80m\n",
    "plt.loglog(f[2:5000], Pxx_den[2:5000])\n",
    "plt.loglog(f[2:5000], f[2:5000]**(-2.4)/100000)\n",
    "#plt.semilogy(f[2:200], Pxx_den[2:200])\n",
    "plt.xlabel('frequency [km]')\n",
    "plt.ylabel('PSD [kg/m^3 /km]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# okay, now do all the USV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_all=[]\n",
    "for iusv in range(3):\n",
    "    ds_usv = ds.isel(trajectory=0)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "    dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08)\n",
    "    ds4 = ds3.interp(dist_total=dist_interp)\n",
    "    den = ds4.density_mean.interpolate_na(dim='dist_total')\n",
    "    ds4_detrend = signal.detrend(den)\n",
    "    ds4_detrend_smooth = scipy.ndimage.filters.gaussian_filter1d(ds4_detrend, sigma=25)\n",
    "    f, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/.080)  #fs = sampled at .08km or 80m\n",
    "    if iusv==0:\n",
    "        data_all=ds4_detrend_smooth\n",
    "        ps_all=Pxx_den[0:10000]\n",
    "    else:\n",
    "        data_all = np.concatenate([data_all,ds4_detrend_smooth])\n",
    "        ps_all = np.vstack([ps_all,Pxx_den[0:10000]])\n",
    "    print(iusv)\n",
    "f, Pxx_den = signal.periodogram(data_all[:101000],1/.080)  #fs = sampled at .08km or 80m\n",
    "plt.loglog(f[5:900], Pxx_den[5:900])\n",
    "plt.loglog(f[5:900], f[5:900]**(-2.4)/100000)\n",
    "plt.xlabel('frequency [km]')\n",
    "plt.ylabel('PSD [kg/m^3 /km]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Pxx_den = np.mean(ps_all,axis=0)\n",
    "#f, Pxx_den = signal.periodogram(data_all[:101000],1/.080)  #fs = sampled at .08km or 80m\n",
    "plt.loglog(f[5:900], Pxx_den[5:900])\n",
    "plt.loglog(f[5:900], f[5:900]**(-2.4)/100000)\n",
    "plt.xlabel('frequency [km]')\n",
    "plt.ylabel('PSD [kg/m^3 /km]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iusv in range(3):\n",
    "    len2=0.1\n",
    "    ds_usv = ds.isel(trajectory=iusv)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)  #add dist traveled coordinate\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})                  #swap from time to distance traveled\n",
    "    dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],len2)\n",
    "    ds4 = ds3.interp(dist_total=dist_interp)       \n",
    "    den_grad =  np.abs(np.gradient(ds4.density_mean)/len2)\n",
    "    print(np.nanmax(den_grad))\n",
    "    print('dist:',dist_interp.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iusv in range(3):\n",
    "    len2=0.1\n",
    "    ds_usv = ds.isel(trajectory=iusv)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)  #add dist traveled coordinate\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})                  #swap from time to distance traveled\n",
    "    dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],len2)\n",
    "    ds4 = ds3.interp(dist_total=dist_interp)       \n",
    "    den_grad =  np.abs(np.gradient(ds4.density_mean)/len2)\n",
    "    print(np.nanmax(den_grad))\n",
    "    print('dist:',dist_interp.max())\n",
    "    plt.plot(den_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iusv in range(3):\n",
    "    len2=0.1\n",
    "    ds_usv = ds.isel(trajectory=iusv)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)  #add dist traveled coordinate\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})                  #swap from time to distance traveled\n",
    "    dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],len2)\n",
    "    ds4 = ds3.interp(dist_total=dist_interp)       \n",
    "    den_grad =  np.abs(np.gradient(ds4.SAL_SBE37_MEAN)/len2)\n",
    "    print(np.nanmax(den_grad))\n",
    "    print('dist:',dist_interp.max())\n",
    "    plt.plot(den_grad)    \n",
    "    plt.plot(ds4.SAL_SBE37_MEAN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g1=abs(np.gradient(ds2.density_mean))/0.08\n",
    "g2=abs(np.gradient(ds4.density_mean))/20\n",
    "r1,x=np.histogram(g1,bins=np.arange(0,0.04,0.001))\n",
    "r2,x=np.histogram(g2,bins=np.arange(0.,0.04,0.001))\n",
    "plt.plot(x[:-1],r1/sum(r1),'r')\n",
    "plt.plot(x[:-1],r2/sum(r2),'b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(ds2.dist_total,ds2.density_mean,'r')\n",
    "plt.plot(ds4.dist_total,ds4.density_mean,'b.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iusv in range(3):\n",
    "    len2=0.1\n",
    "    ds_usv = ds.isel(trajectory=iusv)\n",
    "    plt.plot(ds_usv.time,ds_usv.SAL_SBE37_MEAN,label=ds_usv.trajectory.data)\n",
    "    plt.legend()\n",
    "    plt.xticks(rotation=45) \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(8,12))\n",
    "ax = plt.axes(projection = ccrs.PlateCarree())  # create a set of axes with Mercator projection\n",
    "for i in range(3):\n",
    "    ds2 = ds.isel(trajectory=i)\n",
    "    im=ax.scatter(ds2.longitude,ds2.latitude,c=ds2.SAL_SBE37_MEAN,vmin=34,vmax=36,\n",
    "                  s=.15,transform=ccrs.PlateCarree(),label=ds2.trajectory.data,cmap='jet')\n",
    "    ax.coastlines(resolution='10m')                \n",
    "    ax.set_extent([-64,-46,4,16])\n",
    "    #ax.legend()\n",
    "cax = fig.add_axes([0.5, 0.6, 0.3, 0.02])\n",
    "cbar = fig.colorbar(im,cax=cax, orientation='horizontal')\n",
    "cbar.set_label('Salinity (psu)')\n",
    "fig.savefig(figs_dir+'map_sss_nasa.png')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make arrays for sampling at different length scales\n",
    "\n",
    "sat_str = 'rss_40km'\n",
    "data_in = ds_rss\n",
    "data_in['density_mean']=data_in.sss_smap.copy(deep=True)\n",
    "for iusv in range(3):   \n",
    "    tem=sw.dens0(data_in.sss_smap_40km[iusv,:],data_in.surtep[iusv,:]-273.15) #ds.TEMP_SBE37_MEAN[iusv,:])\n",
    "    data_in['density_mean'][iusv,:]=tem\n",
    "data_in['dist_total']=ds.dist_total\n",
    "\n",
    "data_all=[]\n",
    "for iusv in range(3):\n",
    "    ds_usv = data_in.isel(trajectory=iusv)\n",
    "    ds_usv['dist_total']=ds.isel(trajectory=iusv).dist_total\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "    dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08)\n",
    "    ds4 = ds3.interp(dist_total=dist_interp)\n",
    "    den = ds4.density_mean.interpolate_na(dim='dist_total')\n",
    "    den = den.where(np.isfinite(den),drop=True)\n",
    "    ds4_detrend = signal.detrend(den)\n",
    "    ds4_detrend_smooth = scipy.ndimage.filters.gaussian_filter1d(ds4_detrend, sigma=25)\n",
    "    f, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/.080)  #fs = sampled at .08km or 80m\n",
    "    if iusv==0:\n",
    "        data_all=ds4_detrend_smooth\n",
    "        ps_all=Pxx_den[0:10000]\n",
    "    else:\n",
    "        data_all = np.concatenate([data_all,ds4_detrend_smooth])\n",
    "        ps_all = np.vstack([ps_all,Pxx_den[0:10000]])\n",
    "    print(iusv)\n",
    "f, Pxx_den = signal.periodogram(data_all[:101000],1/.080)  #fs = sampled at .08km or 80m\n",
    "\n",
    "\n",
    "length_scale = np.arange(.1,100,1)\n",
    "# create the empty data arrays to store the normalized histograms (normalized the *100 for percentage count)\n",
    "xx_in = np.arange(0,.04,.001)\n",
    "xx_in2 = np.arange(0,.04-.001,.001)\n",
    "data = np.zeros((len(length_scale),len(xx_in2)))\n",
    "ddn=xr.DataArray(data,dims=('length_scale','gradx'),coords={'length_scale':length_scale,'gradx':xx_in2})\n",
    "for iusv in range(3):\n",
    "    ds_usv = data_in.isel(trajectory=iusv)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)  #add dist traveled coordinate\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})                  #swap from time to distance traveled\n",
    "    for ilen2,len2 in enumerate(length_scale):\n",
    "        dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],len2)\n",
    "        ds4 = ds3.interp(dist_total=dist_interp)       \n",
    "        den_grad =  np.abs(np.gradient(ds4.density_mean)/len2)\n",
    "        result,xx = np.histogram(den_grad,bins=xx_in)\n",
    "        ddn[ilen2,:]=ddn[ilen2,:]+result\n",
    "for ilen2,len2 in enumerate(length_scale):\n",
    "    ddn[ilen2,:]=ddn[ilen2,:]/sum(ddn[ilen2,:])*100  #normalize & turn into percent\n",
    "    \n",
    "print(len(length_scale),len(xx_in))\n",
    "fig = plt.figure(figsize=(14,10))\n",
    "tem=ddn\n",
    "tem = tem.where(tem>.003)\n",
    "Z=tem.T\n",
    "ax = plt.pcolormesh(length_scale,xx_in2,Z, norm=colors.LogNorm(vmin=Z.min(), vmax=Z.max()),vmin=.01,vmax=100,cmap='hot')\n",
    "plt.text(25,0.036,'(a)'+sat_str,fontsize=16,color='k')\n",
    "plt.xlabel('Length scale (km)',fontsize=16)\n",
    "plt.ylabel('Density gradient (kg m$^{-3}$ km$^{-1}$)',fontsize=16)\n",
    "cb = plt.colorbar()\n",
    "cb.set_label(label='Percent count',fontsize=16)\n",
    "\n",
    "\n",
    "plt.axes([.43, .57, .3, .3])\n",
    "\n",
    "\n",
    "#cal PSD\n",
    "Pxx_den = np.mean(ps_all,axis=0)\n",
    "#f, Pxx_den = signal.periodogram(Pxx_den,1/.080)  #fs = sampled at .08km or 80m\n",
    "istart,iend=10,5550\n",
    "plt.loglog(f[istart:iend], Pxx_den[istart:iend])\n",
    "\n",
    "#linear regression to PSD\n",
    "istart,iend=10,1000\n",
    "XX = np.log(f[istart:iend])\n",
    "YY = np.log(Pxx_den[istart:iend])\n",
    "reg = LinearRegression().fit(XX.reshape(-1, 1), YY)\n",
    "a = float(reg.coef_)\n",
    "b = -1*float(reg.intercept_)\n",
    "plt.loglog(f[istart:iend], f[istart:iend]**(a)/np.exp(b),'r') #test from fit\n",
    "slp_str = 'slope = '+\"{:.1f}\".format(a)\n",
    "plt.text(.02,.1,slp_str,fontsize=16,color='r')\n",
    "plt.ylim([10e-6,10e1])\n",
    "plt.xlim([10e-4,10e-1])\n",
    "\n",
    "plt.text(.002,20,'(b)',fontsize=16,color='k')\n",
    "plt.xlabel('Wavenumber (cpkm)')\n",
    "plt.ylabel('PSD ((kg m$^{-3}$)$^2$ cpkm$^{-1}$)')\n",
    "plt.grid()\n",
    "plt.savefig(figs_dir+'PSD_den_grad_sat_'+sat_str+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istart,iend=10,32\n",
    "print(1/f[istart],1/f[iend])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "istart,iend=10,115\n",
    "print(1/f[istart],1/f[iend])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ilen2=120\n",
    "ds_usv = ds.isel(trajectory=0)\n",
    "ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],ilen2)\n",
    "ds4 = ds3.interp(dist_total=dist_interp)\n",
    "ds5 = ds4.interp(dist_total=np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds3.sel(dist_total=slice(3700,4200)).SAL_SBE37_MEAN.plot()\n",
    "ds5.sel(dist_total=slice(3700,4200)).SAL_SBE37_MEAN.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = ds\n",
    "data_all=[]\n",
    "for iusv in range(1):\n",
    "    ds_usv = data_in.isel(trajectory=iusv)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "    dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08)\n",
    "    ds4 = ds3.interp(dist_total=dist_interp)\n",
    "    den = ds4.density_mean.interpolate_na(dim='dist_total')\n",
    "    den = den.where(np.isfinite(den),drop=True)\n",
    "    ds4_detrend = signal.detrend(den)\n",
    "    ds4_detrend_smooth = scipy.ndimage.filters.gaussian_filter1d(ds4_detrend, sigma=25)\n",
    "    freq, Pxx_den = signal.periodogram(ds4_detrend_smooth,1/.080)  #fs = sampled at .08km or 80m\n",
    "    if iusv==0:\n",
    "        data_all=ds4_detrend_smooth\n",
    "        ps_all=Pxx_den[0:10000]\n",
    "    else:\n",
    "        data_all = np.concatenate([data_all,ds4_detrend_smooth])\n",
    "        ps_all = np.vstack([ps_all,Pxx_den[0:10000]])\n",
    "plt.loglog(freq[10:1000],Pxx_den[10:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_in = ds\n",
    "data_all=[]\n",
    "for iusv in range(1):\n",
    "    ds_usv = data_in.isel(trajectory=iusv)\n",
    "    ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "    ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "    dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08)\n",
    "    ds4 = ds3.interp(dist_total=dist_interp)\n",
    "    den = ds4.density_mean.interpolate_na(dim='dist_total')\n",
    "    den = den.where(np.isfinite(den),drop=True)\n",
    "    ds4_detrend = signal.detrend(den)\n",
    "    ds4_detrend_smooth = scipy.ndimage.filters.gaussian_filter1d(ds4_detrend, sigma=25)\n",
    "    #f, Pxx_den = signal.welch(x, fs, nperseg=1024)\n",
    "    freq2, Pxx_den2 = signal.welch(ds4_detrend_smooth,1/.080,nperseg=1024*30)  #fs = sampled at .08km or 80m\n",
    "#plt.loglog(freq2[10:1000],Pxx_den2[10:1000])\n",
    "plt.loglog(freq[10:900],Pxx_den[10:900])\n",
    "plt.loglog(freq2[5:200],Pxx_den2[5:200],'r')\n",
    "\n",
    "#linear regression to PSD\n",
    "istart,iend=5,200\n",
    "XX = np.log(freq2[istart:iend])\n",
    "YY = np.log(Pxx_den2[istart:iend])\n",
    "reg = LinearRegression().fit(XX.reshape(-1, 1), YY)\n",
    "a = float(reg.coef_)\n",
    "b = -1*float(reg.intercept_)\n",
    "plt.loglog(freq2[istart:iend], freq2[istart:iend]**(a)/np.exp(b),'k') #test from fit\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(1/freq2[200])\n",
    "print(0.08*25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_adcp = 'C:/Users/gentemann/Google Drive/public/2019_saildrone/ATOMIC/adcp/sd-1026/'\n",
    "ds_adcp = xr.open_mfdataset(dir_adcp+'*.nc',combine='nested',concat_dim='obs')\n",
    "ds_adcp.close()\n",
    "ds_adcp=ds_adcp.isel(trajectory=0).swap_dims({'obs':'time'})\n",
    "xlat=ds_adcp.latitude\n",
    "xlon=ds_adcp.longitude\n",
    "dkm2 = abs(np.abs((((xlon[1:].data-xlon[0:-1].data)**2+(xlat[1:].data-xlat[0:-1].data)**2)**.5)*110.567*np.cos(np.pi*xlat[1:].data/180)))\n",
    "dkm2=np.append(dkm2,dkm2[9214]) #add on last point\n",
    "dkm3 = dkm2.cumsum()\n",
    "ds_adcp['dist_total']=xr.DataArray(dkm3,dims=('time'),coords={'time':ds_adcp.time})\n",
    "ds_adcp['dist_between']=xr.DataArray(dkm2,dims=('time'),coords={'time':ds_adcp.time})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_adcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds_in,ds_rss_in,ds_jpl_in,str2,offset):\n",
    "    import math\n",
    "    iusv=0\n",
    "    ds_usv = ds_in.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "    print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "    ll=[]\n",
    "    for i in range(3750,4450,100):\n",
    "        ll.append(\"{:.0f}\".format(i))\n",
    "    print(ll)\n",
    "    fig,(ax0)= plt.subplots(1,1,figsize=(15,6))\n",
    "    for iusv in range(1):\n",
    "        ds_usv = ds.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "        ax0.plot(ds_usv.time,ds_usv[var1],label=ds_usv.trajectory.data)\n",
    "    ds_usv = ds_jpl_in.isel(trajectory=0).sel(time=slice(t1,t2))\n",
    "    ax0.plot(ds_usv.time,ds_usv[var2]+offset,label='JPL')\n",
    "    ds_usv = ds_rss_in.isel(trajectory=0).sel(time=slice(t1,t2))\n",
    "    ax0.plot(ds_usv.time,ds_usv[var3]+offset,label='RSS')\n",
    "    ax0.plot(ds_usv.time,ds_usv[var4]+offset,label='RSS 40 km')\n",
    "    ax0.legend()\n",
    "    ax0.set_ylabel(ystr)\n",
    "    ax0.set_xlabel('Date')\n",
    "#    ax0.set_xlim([np.datetime64(t1),np.datetime64(t2)])\n",
    "    ax0.set_xlim([t1,t2])\n",
    "\n",
    "    pos = ax0.get_position()\n",
    "#    pos.y0 = pos.y0+.04       # for example 0.2, choose your value\n",
    "    ax0.set_position(pos)\n",
    "    ax2 = ax0.twiny()\n",
    "    # Move twinned axis ticks and label from top to bottom\n",
    "    ax2.xaxis.set_ticks_position(\"top\")\n",
    "    ax2.xaxis.set_label_position(\"top\")\n",
    "    # Offset the twin axis below the host\n",
    "#    ax2.spines[\"bottom\"].set_position((\"axes\", -0.06))\n",
    "    ax1Ticks = ax0.get_xticks()   \n",
    "    ax2Ticks = ax1Ticks\n",
    "    \n",
    "    #calculate new ticks\n",
    "    temdist = ds_usv.dist_total.data\n",
    "    print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "    tem = np.arange(math.ceil(ds_usv.dist_total[0].data/50)*50,math.floor(ds_usv.dist_total[-1].data/50)*50+60,100)\n",
    "    ll=[]\n",
    "    for i in tem: #range(3750,4450,100):\n",
    "        ll.append(\"{:.0f}\".format(i))\n",
    "    isv=[]\n",
    "    for i in tem:\n",
    "        ii = np.argwhere((ds_usv.dist_total.data.astype(int))==i)\n",
    "        if len(ii)>0:\n",
    "            isv.append(int(ii.mean())/len(temdist))   \n",
    "    \n",
    "    new_tick_locations = isv\n",
    "    print(new_tick_locations)\n",
    "    ax2.set_xticks(new_tick_locations)\n",
    "    ax2.set_xticklabels(ll)\n",
    "    ax2.set_xlabel('distance along track (km)')\n",
    "    #plt.savefig(figs_dir+ 'timeseries_'+str(t1)+'eddy'+str2+'.png')\n",
    "\n",
    "t1,t2 = np.datetime64('2020-02-15T09'),np.datetime64('2020-02-21T00')\n",
    "offset=0\n",
    "var1,var2,var3,var4,ystr= 'SAL_SBE37_MEAN','smap_sss','sss_smap','sss_smap_40km','Salinity (psu)'\n",
    "ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds_saildrone,ds_rss_usv,ds_jpl_usv,'salinity',offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds_in,ds_rss_in,ds_jpl_in,str2,offset):\n",
    "    import math\n",
    "    iusv=0\n",
    "    ds_usv = ds_in.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "    print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "    ll=[]\n",
    "    for i in range(3750,4450,100):\n",
    "        ll.append(\"{:.0f}\".format(i))\n",
    "    print(ll)\n",
    "    fig,(ax0)= plt.subplots(1,1,figsize=(15,6))\n",
    "    for iusv in range(1):\n",
    "        ds_usv = ds.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "        ax0.plot(ds_usv.time,ds_usv[var1],label=ds_usv.trajectory.data)\n",
    "    ds_usv = ds_jpl_in.isel(trajectory=0).sel(time=slice(t1,t2))\n",
    "    ax0.plot(ds_usv.time,ds_usv[var2]+offset,label='JPL')\n",
    "    ds_usv = ds_rss_in.isel(trajectory=0).sel(time=slice(t1,t2))\n",
    "    ax0.plot(ds_usv.time,ds_usv[var3]+offset,label='RSS')\n",
    "    ax0.plot(ds_usv.time,ds_usv[var4]+offset,label='RSS 40 km')\n",
    "    ax0.legend()\n",
    "    ax0.set_ylabel(ystr)\n",
    "    ax0.set_xlabel('Date')\n",
    "#    ax0.set_xlim([np.datetime64(t1),np.datetime64(t2)])\n",
    "    ax0.set_xlim([t1,t2])\n",
    "\n",
    "    pos = ax0.get_position()\n",
    "#    pos.y0 = pos.y0+.04       # for example 0.2, choose your value\n",
    "    ax0.set_position(pos)\n",
    "    ax2 = ax0.twiny()\n",
    "    # Move twinned axis ticks and label from top to bottom\n",
    "    ax2.xaxis.set_ticks_position(\"top\")\n",
    "    ax2.xaxis.set_label_position(\"top\")\n",
    "    # Offset the twin axis below the host\n",
    "#    ax2.spines[\"bottom\"].set_position((\"axes\", -0.06))\n",
    "    ax1Ticks = ax0.get_xticks()   \n",
    "    ax2Ticks = ax1Ticks\n",
    "    \n",
    "    #calculate new ticks\n",
    "    temdist = ds_usv.dist_total.data\n",
    "    print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "    tem = np.arange(math.ceil(ds_usv.dist_total[0].data/50)*50,math.floor(ds_usv.dist_total[-1].data/50)*50+60,100)\n",
    "    ll=[]\n",
    "    for i in tem: #range(3750,4450,100):\n",
    "        ll.append(\"{:.0f}\".format(i))\n",
    "    isv=[]\n",
    "    for i in tem:\n",
    "        ii = np.argwhere((ds_usv.dist_total.data.astype(int))==i)\n",
    "        if len(ii)>0:\n",
    "            isv.append(int(ii.mean())/len(temdist))   \n",
    "    \n",
    "    new_tick_locations = isv\n",
    "    print(new_tick_locations)\n",
    "    ax2.set_xticks(new_tick_locations)\n",
    "    ax2.set_xticklabels(ll)\n",
    "    ax2.set_xlabel('distance along track (km)')\n",
    "\n",
    "#    ds_tem = ds_adcp.sel(time=slice(t1,t2))\n",
    "#    rx = ds_tem.dist_total#-ds_tem.dist_total[0]+ds_usv.dist_total[0]\n",
    "#    rx = rx[::15]\n",
    "#    ry=np.ones(len(rx))*31.5\n",
    "#    dx,dy = ds_tem.vel_east[::15,0], ds_tem.vel_north[::15,0]\n",
    "#    ax2.quiver(rx,ry,dx,dy,scale=10)\n",
    "\n",
    "    #add scale arrow\n",
    "#    ax2.quiver(ds_usv.dist_total[0],31.8,1,0,scale=10)\n",
    "#    ax2.text(ds_usv.dist_total[0],32,'1 m/s')\n",
    "#    ax2.set_ylim([30,38])\n",
    "\n",
    "\n",
    "    \n",
    "    #plt.savefig(figs_dir+ 'timeseries_'+str(t1)+'eddy'+str2+'.png')\n",
    "\n",
    "t1,t2 = np.datetime64('2020-02-15T09'),np.datetime64('2020-02-21T00')\n",
    "offset=0\n",
    "var1,var2,var3,var4,ystr= 'SAL_SBE37_MEAN','smap_sss','sss_smap','sss_smap_40km','Salinity (psu)'\n",
    "ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds_saildrone,ds_rss_usv,ds_jpl_usv,'salinity',offset)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t1,t2 = np.datetime64('2020-02-15T09'),np.datetime64('2020-02-21T00')\n",
    "offset=0\n",
    "var1,var2,var3,var4,ystr= 'SAL_SBE37_MEAN','smap_sss','sss_smap','sss_smap_40km','Salinity (psu)'\n",
    "#ts_plot(t1,t2,var1,var2,var3,var4,ystr,figs_dir,ds_saildrone,ds_rss_usv,ds_jpl_usv,'salinity',offset)\n",
    "#tem=ds_saildrone.sel(time=slice(t1,t2))\n",
    "\n",
    "#tem = ds_adcp.sel(time=slice(t1,t2))\n",
    "import math\n",
    "iusv=0\n",
    " \n",
    "ds_usv = ds_saildrone.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "print(ds_usv.dist_total[0].data,ds_usv.dist_total[-1].data)\n",
    "ll=[]\n",
    "for i in range(3750,4450,100):\n",
    "    ll.append(\"{:.0f}\".format(i))\n",
    "print(ll)\n",
    "fig,(ax0)= plt.subplots(1,1,figsize=(15,9))\n",
    "ds_usv = ds.isel(trajectory=iusv).sel(time=slice(t1,t2))\n",
    "ax0.plot(ds_usv.dist_total,ds_usv[var1],'b',label=var1)\n",
    "\n",
    "ds_tem = ds_adcp.sel(time=slice(t1,t2))\n",
    "rx = ds_tem.dist_total-ds_tem.dist_total[0]+ds_usv.dist_total[0]\n",
    "rx = rx[::15]\n",
    "ry=np.ones(len(rx))*31.5\n",
    "dx,dy = ds_tem.vel_east[::15,0], ds_tem.vel_north[::15,0]\n",
    "ax0.quiver(rx,ry,dx,dy,scale=10)\n",
    "\n",
    "rx = ds_usv.dist_total\n",
    "rx = rx[::85]\n",
    "ry=np.ones(len(rx))*37.5\n",
    "dx,dy = ds_usv.UWND_MEAN[::85], ds_usv.VWND_MEAN[::85]\n",
    "ax0.quiver(rx,ry,dx,dy,scale=170,color='g')\n",
    "\n",
    "#add scale arrow\n",
    "ax0.quiver(ds_usv.dist_total[0],31.8,1,0,scale=10)\n",
    "ax0.text(ds_usv.dist_total[0],32,'1 m/s')\n",
    "ax0.set_ylim([31,38])\n",
    "\n",
    "ax0a=ax0.twinx()\n",
    "ax0a.plot(ds_usv.dist_total,ds_usv.TEMP_SBE37_MEAN,'r',label='SST')\n",
    "#ax0a.plot(ds_usv.dist_total,ds_usv.TEMP_AIR_MEAN,'r',label='Air')\n",
    "ax0a.set_ylim([26.7,27.7])\n",
    "ax0a.set_ylabel('SST (K)',color='r',fontsize=12)\n",
    "ax0a.tick_params(axis='y', colors='red')\n",
    "ax0.set_ylabel('SSS (psu)',color='b',fontsize=12)\n",
    "ax0.tick_params(axis='y', colors='b')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv.TEMP_AIR_MEAN.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tem.time[0:10].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.arrow([0,1],[0, 0],[0.5,0.5],[0.5,0.5], head_width=0.05, head_length=0.1, fc='k', ec='k')\n",
    "plt.quiver([0,1,2,3,4],[0,0,0,0,0],np.ones(5)*.5,np.ones(5)*.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_usv.attrs['drone_id']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for iusv in range(3):\n",
    "    fname=saildrone_filenames[iusv]\n",
    "    ds_usv=xr.open_dataset(fname).isel(trajectory=0).swap_dims({'obs':'time'})\n",
    "    ds_usv.close()\n",
    "    print(ds_usv.attrs['drone_id'],ds_usv.attrs['wmo_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iusv=0\n",
    "data_in=ds_saildrone\n",
    "data_in['rss']=ds_rss_usv.sss_smap\n",
    "data_in['rss40']=ds_rss_usv.sss_smap_40km\n",
    "data_in['jpl']=ds_jpl_usv.smap_sss\n",
    "ds_usv = data_in.isel(trajectory=iusv)\n",
    "ds2 = ds_usv.assign_coords(dist_total = ds_usv.dist_total)\n",
    "ds3 = ds2.swap_dims({'time':'dist_total'})\n",
    "dist_interp = np.arange(ds2.dist_total[0],ds2.dist_total[-1],0.08)\n",
    "ds4 = ds3.interp(dist_total=dist_interp)\n",
    "den = ds4.SAL_SBE37_MEAN.interpolate_na(dim='dist_total')\n",
    "denr = ds4.rss.interpolate_na(dim='dist_total')\n",
    "denr4 = ds4.rss40.interpolate_na(dim='dist_total')\n",
    "denj = ds4.jpl.interpolate_na(dim='dist_total')\n",
    "#den = den.where(np.isfinite(den),drop=True)\n",
    "ds4a = scipy.ndimage.filters.gaussian_filter1d(den, sigma=25*20)\n",
    "den.plot()\n",
    "denr.plot()\n",
    "#denr4.plot()\n",
    "denj.plot()\n",
    "plt.plot(den.dist_total,ds4a)\n",
    "plt.xlim([3500,5500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.08*25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
